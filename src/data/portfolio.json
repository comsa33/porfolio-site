{
  "profile": {
    "name": {
      "ko": "ì´ë£¨ì˜¤",
      "en": "Ruo Lee"
    },
    "title": "AI Agent Platform Developer",
    "email": "comsa333@gmail.com",
    "github": "https://github.com/comsa33",
    "linkedin": "https://www.linkedin.com/in/ruo-lee-79864522a",
    "story": {
      "ko": "ë””ìì´ë„ˆë¡œ ì‹œì‘í•´ 34ê°œêµ­ì„ ì—¬í–‰í•˜ë©° ì–»ì€ í†µì°°ì„, ì´ì œ AI ê¸°ìˆ ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤",
      "en": "From Designer to World Traveler to AI Engineer â€” Building Intelligent Systems with Global Perspective"
    },
    "intro": {
      "ko": "ê¸°ìˆ ì˜ ê¸°ë³¸ ì›ë¦¬ë¡œ ë¬¸ì œì˜ ë³¸ì§ˆì„ í•´ê²°í•˜ëŠ” AI ì—ì´ì „íŠ¸ í”Œë«í¼ ê°œë°œìì…ë‹ˆë‹¤. ë””ìì¸ì„ ì „ê³µí•˜ê³  ì„¸ê³„ë¥¼ ì—¬í–‰í•˜ë©° ì–»ì€ ë„“ì€ ì‹œì•¼ë¡œ, ì‚¬ìš©ì ê²½í—˜ê³¼ ê¸°ìˆ ì˜ ì¡°í™”ë¥¼ ì¶”êµ¬í•©ë‹ˆë‹¤.",
      "en": "An AI Agent Platform Developer who solves the essence of problems through fundamental technology principles. With a background in Visual Design and a global perspective from world travel, I strive for harmony between User Experience and Technology."
    },
    "coreSkills": {
      "backend": {
        "title": {
          "ko": "Backend & Infrastructure",
          "en": "Backend & Infrastructure"
        },
        "skills": ["Python", "FastAPI", "Redis", "Docker", "Kubernetes"]
      },
      "ai": {
        "title": {
          "ko": "AI & LLM",
          "en": "AI & LLM"
        },
        "skills": ["LLM Agent", "RAG Pipeline", "LLM Integration", "Prompt Eng."]
      },
      "system": {
        "title": {
          "ko": "System Design",
          "en": "System Design"
        },
        "skills": ["Async/Await", "Multiprocessing", "WebSocket", "Concurrency"]
      }
    }
  },
  "timeline": [
    {
      "id": "edudesign",
      "date": "2003.03 - 2012.08",
      "title": {
        "ko": "ì „ë‚¨ëŒ€í•™êµ",
        "en": "Chonnam National Univ."
      },
      "role": {
        "ko": "ì‹œê°ë””ìì¸ ì „ê³µ",
        "en": "Visual Design Major"
      },
      "type": "Education",
      "description": {
        "ko": "ë””ìì¸ì  ì‚¬ê³ ì™€ ì‹œê°ì  ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ëŠ¥ë ¥ í•¨ì–‘.",
        "en": "Developed design thinking and visual communication skills."
      }
    },
    {
      "id": "design-biennale",
      "date": "2009.09 - 2009.11",
      "title": {
        "ko": "2009 ê´‘ì£¼ë””ìì¸ë¹„ì—”ë‚ ë ˆ",
        "en": "2009 Gwangju Design Biennale"
      },
      "role": {
        "ko": "ì¶œí’ˆì‘ê°€",
        "en": "Exhibiting Artist"
      },
      "type": "Design",
      "description": {
        "ko": "ì£¼ì œ 'The Clue-ë”í•  ë‚˜ìœ„ ì—†ëŠ”' ì „ì‹œì— ì‘í’ˆ 2ì  ì¶œí’ˆ.",
        "en": "Exhibited 2 works at 'The Clue' themed exhibition."
      }
    },
    {
      "id": "career-english-edu",
      "date": "2011.05 - 2020.08",
      "title": {
        "ko": "ì˜ì–´ êµìœ¡ ë¶„ì•¼ ê²½ë ¥",
        "en": "English Education Career"
      },
      "role": {
        "ko": "ì–´í•™ì› ì„¤ë¦½/ìš´ì˜ ë° ì „ì„ê°•ì‚¬",
        "en": "Founder & Instructor"
      },
      "type": "Career",
      "description": {
        "ko": "í† ìµì‰½/ê³ íŒŒí† ìµ ì–´í•™ì› ì„¤ë¦½ ë° ìš´ì˜. ëŒ€í•™ ë° êµìœ¡ê¸°ê´€ì—ì„œ ì˜ì–´ íšŒí™” ë° í† ìµ ê°•ì˜ (9ë…„).",
        "en": "Founded and operated 2 language institutes. Taught TOEIC and English conversation at universities (9 years)."
      }
    },
    {
      "id": "world-travel",
      "date": "2016.08 ~ 2017.07",
      "title": {
        "ko": "ì„¸ê³„ì¼ì£¼",
        "en": "World Travel"
      },
      "role": {
        "ko": "ê²½ë ¥ íœ´ì‹ê¸°",
        "en": "Career Break"
      },
      "type": "Travel",
      "description": {
        "ko": "32ê°œêµ­ ë°°ë‚­ì—¬í–‰. ë‹¤ì–‘í•œ ë¬¸í™” ì²´í—˜ ë° ê¸€ë¡œë²Œ ë§ˆì¸ë“œì…‹ í•¨ì–‘.",
        "en": "Backpacked through 32 countries. Experienced diverse cultures and cultivated a global mindset."
      },
      "paperLink": "https://backpacking.po24lio.com/",
      "paperTitle": {
        "ko": "ì—¬í–‰ ìŠ¤í† ë¦¬",
        "en": "Travel Story"
      }
    },
    {
      "id": "edu-kcyber",
      "date": "2020.03 - 2023.08",
      "title": {
        "ko": "ê³ ë ¤ì‚¬ì´ë²„ëŒ€í•™êµ",
        "en": "Korea Cyber University"
      },
      "role": {
        "ko": "ì¸ê³µì§€ëŠ¥ ì „ê³µ (í•™ì‚¬)",
        "en": "AI Major (Bachelor)"
      },
      "type": "Education",
      "description": {
        "ko": "â€¢ í•™ì  4.3/4.5",
        "en": "â€¢ GPA 4.3/4.5"
      },
      "paperLink": "https://kiss.kstudy.com/Detail/Ar?key=4028402",
      "paperTitle": {
        "ko": "í•™ì‚¬ ë…¼ë¬¸",
        "en": "Bachelor's Thesis"
      }
    },
    {
      "id": "edu-kcci",
      "date": "2021.03 - 2021.07",
      "title": {
        "ko": "ëŒ€í•œìƒê³µíšŒì˜ì†Œ",
        "en": "Korea Chamber of Commerce"
      },
      "role": {
        "ko": "AI ì†Œí”„íŠ¸ì›¨ì–´ í”„ë¡œê·¸ë˜ë°",
        "en": "AI Software Programming"
      },
      "type": "Education",
      "description": {
        "ko": "Python í”„ë¡œê·¸ë˜ë°, ë°ì´í„° ìˆ˜ì§‘/ë¶„ì„ ë° RDBMS í™œìš© ëŠ¥ë ¥ ìŠµë“.",
        "en": "Learned Python programming, data collection/analysis, and RDBMS skills."
      }
    },
    {
      "id": "edu-codestates",
      "date": "2021.09 - 2022.04",
      "title": {
        "ko": "ì½”ë“œìŠ¤í…Œì´ì¸ ",
        "en": "Code States"
      },
      "role": {
        "ko": "AI ë¶€íŠ¸ìº í”„",
        "en": "AI Bootcamp"
      },
      "type": "Education",
      "description": {
        "ko": "ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ í”„ë¡œì íŠ¸ ë° Data Engineering/MLOps ì‹¤ë¬´ ê²½í—˜.",
        "en": "Practical experience in ML/DL projects and Data Engineering/MLOps."
      }
    },
    {
      "id": "dev-gravylab",
      "date": "2022.05 - 2023.06",
      "title": {
        "ko": "ê·¸ë ˆì´ë¹„ë©",
        "en": "GravyLab"
      },
      "role": {
        "ko": "ë°ì´í„°ì—”ì§€ë‹ˆì–´ (ì„ ì„ì—°êµ¬ì›)",
        "en": "Data Engineer"
      },
      "type": "Dev",
      "description": {
        "ko": "â€¢ êµ¬ì§ì-ê¸°ì—… ë§¤ì¹­ ML ëª¨ë¸ ê°œë°œ ë° íŠ¹í—ˆ ë“±ë¡\nâ€¢ ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•\nâ€¢ ëŒ€ê·œëª¨ ì›¹í¬ë¡¤ëŸ¬ ê°œë°œ",
        "en": "â€¢ Developed job seeker-company matching ML model (patent registered)\nâ€¢ Built data pipelines\nâ€¢ Developed large-scale web crawlers"
      },
      "paperLink": "https://patentimages.storage.googleapis.com/3c/c8/73/b770f95a418ac0/KR102721044B1.pdf",
      "paperTitle": {
        "ko": "íŠ¹í—ˆ: êµ¬ì§ì ì¶”ì²œ ì‹œìŠ¤í…œ",
        "en": "Patent: Job Seeker Recommendation System"
      }
    },
    {
      "id": "dev-illunex",
      "date": "2023.11 - 2024.07",
      "title": {
        "ko": "ì¼ë£¨ë„¥ìŠ¤",
        "en": "Illunex"
      },
      "role": {
        "ko": "ë°ì´í„°ì—”ì§€ë‹ˆì–´ (AI íŒ€)",
        "en": "Data Engineer"
      },
      "type": "Dev",
      "description": {
        "ko": "â€¢ íŠ¹í—ˆ/ë‰´ìŠ¤ ì±—ë´‡ì„ ìœ„í•œ RAG ì‹œìŠ¤í…œ ê°œë°œ\nâ€¢ ElasticSearch ê¸°ë°˜ ê²€ìƒ‰ Retriever ì„œë²„ êµ¬ì¶•\nâ€¢ ETL íŒŒì´í”„ë¼ì¸ êµ¬ì¶•",
        "en": "â€¢ Developed RAG system for patent/news chatbot\nâ€¢ Built ElasticSearch-based Retriever server\nâ€¢ Built ETL pipelines"
      }
    },
    {
      "id": "dev-posicube",
      "date": "2024.08 - Current",
      "title": {
        "ko": "í¬ì§€íë¸Œ",
        "en": "Posicube"
      },
      "role": {
        "ko": "AI ê°œë°œì (AI ê°œë°œ1íŒ€)",
        "en": "AI Developer (AI Dev Team 1)"
      },
      "type": "Dev",
      "description": {
        "ko": "â€¢ LLM ì—ì´ì „íŠ¸ í”Œë«í¼ í•µì‹¬ ë°±ì—”ë“œ ê°œë°œ\nâ€¢ Python ìƒŒë“œë°•ìŠ¤ ì„œë¹„ìŠ¤ (PyRunner)\nâ€¢ RAG í‰ê°€ ì‹œìŠ¤í…œ (Evaluator)\nâ€¢ ì›¹ IDE (PyEditor)",
        "en": "â€¢ Developing core backend for LLM Agent Platform\nâ€¢ Python sandbox service (PyRunner)\nâ€¢ RAG evaluation system (Evaluator)\nâ€¢ Web IDE (PyEditor)"
      }
    },
    {
      "id": "edu-aSST",
      "date": "2024.09 - 2025.08",
      "title": {
        "ko": "ì„œìš¸ê³¼í•™ì¢…í•©ëŒ€í•™ì›",
        "en": "aSSIST"
      },
      "role": {
        "ko": "AI ë¹…ë°ì´í„° (ì„ì‚¬)",
        "en": "AI Big Data (Master)"
      },
      "type": "Education",
      "description": {
        "ko": "â€¢ AI ë¹…ë°ì´í„° ì„ì‚¬ ê³¼ì •\nâ€¢ í•™ì  4.23/4.3\nâ€¢ ì„ì‚¬ë…¼ë¬¸: ìƒì„±í˜• AI ê¸°ë°˜ ì‹œê³„ì—´ ì˜ˆì¸¡ ìë™í™” ì—°êµ¬",
        "en": "â€¢ Master's in AI Big Data\nâ€¢ GPA 4.23/4.3\nâ€¢ Thesis: Generative AI-based Time Series Forecasting Automation"
      },
      "paperLink": "https://www.kci.go.kr/kciportal/ci/sereArticleSearch/ciSereArtiView.kci?sereArticleSearchBean.artiId=ART003244700",
      "paperTitle": {
        "ko": "ì„ì‚¬ ë…¼ë¬¸",
        "en": "Master's Thesis"
      }
    },
    {
      "id": "edu-sdg",
      "date": "2024.09 - 2025.08",
      "title": {
        "ko": "SDG Management School",
        "en": "SDG Management School"
      },
      "role": {
        "ko": "ê²½ì˜í•™ ì„ì‚¬ (MBA)",
        "en": "Master of Business Administration (MBA)"
      },
      "type": "Education",
      "description": {
        "ko": "ìŠ¤ìœ„ìŠ¤ ê²½ì˜ëŒ€í•™ì› Executive MBA ê³¼ì •.",
        "en": "Executive Master of Business Administration program in Switzerland."
      }
    }
  ],
  "projects": [
    {
      "id": "py-runner",
      "title": "PyRunner",
      "shortDescription": {
        "ko": "ë¶„ì‚°í˜• Python ìƒŒë“œë°•ìŠ¤ & ë™ì  ì—ì´ì „íŠ¸ ëŸ°íƒ€ì„",
        "en": "Distributed Python Sandbox & Dynamic Agent Runtime"
      },
      "fullDescription": {
        "ko": "Multi-Pod í™˜ê²½ì—ì„œ AI ì—ì´ì „íŠ¸ë¥¼ ë™ì ìœ¼ë¡œ ë°°í¬í•˜ê³  ì‹¤í–‰í•˜ëŠ” ê³ ê°€ìš©ì„± í”Œë«í¼ì…ë‹ˆë‹¤. Redis Pub/Sub ê¸°ë°˜ ë¶„ì‚° ë¼ìš°íŒ…ê³¼ FastAPI Sub-app ë™ì  ë¡œë”©ì„ í†µí•´ Zero-downtime ë°°í¬ë¥¼ ì‹¤í˜„í–ˆìŠµë‹ˆë‹¤.",
        "en": "High-availability platform for dynamically deploying and executing AI agents in multi-pod environments. Achieved zero-downtime deployment through Redis Pub/Sub distributed routing and FastAPI sub-app dynamic loading."
      },
      "techStack": ["Python 3.11", "FastAPI", "Redis Pub/Sub", "Docker", "SSE", "Multiprocessing"],
      "keyAchievements": [
        {
          "ko": "Redis Pub/Sub ì´ë²¤íŠ¸ ë²„ìŠ¤ë¡œ Multi-Pod ì‹¤ì‹œê°„ ë°°í¬ ë™ê¸°í™”",
          "en": "Real-time deployment sync across multi-pods via Redis Pub/Sub event bus"
        },
        {
          "ko": "Distributed Lockìœ¼ë¡œ Race Condition í•´ê²° (ë°°í¬ ì‹¤íŒ¨ìœ¨ 0% ë‹¬ì„±)",
          "en": "Resolved race conditions with distributed locks (achieved 0% deployment failure)"
        },
        {
          "ko": "FastAPI Sub-app ë™ì  ë¡œë”©ìœ¼ë¡œ Zero-downtime ë°°í¬ êµ¬í˜„",
          "en": "Implemented zero-downtime deployment with FastAPI sub-app dynamic loading"
        },
        {
          "ko": "SSE ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ LLM í† í° ì‹¤ì‹œê°„ ì¤‘ê³„ (ChatGPT ìŠ¤íƒ€ì¼)",
          "en": "Real-time LLM token streaming via SSE (ChatGPT-style)"
        },
        {
          "ko": "ë©€í‹°í”„ë¡œì„¸ìŠ¤ ì•„í‚¤í…ì²˜ë¡œ Agent/Sandbox/Dev ì„œë²„ ë…ë¦½ì„± ë³´ì¥",
          "en": "Guaranteed independence of Agent/Sandbox/Dev servers with multiprocess architecture"
        }
      ],
      "features": [
        "Dynamic Agent Runtime",
        "Redis-based Distributed Routing",
        "Zero-downtime Deployment",
        "SSE Streaming Pipeline",
        "Secure Sandbox Isolation"
      ],
      "repoPath": "py-runner",
      "company": {
        "ko": "(ì£¼)í¬ì§€íë¸Œ",
        "en": "Posicube Inc."
      },
      "period": {
        "ko": "2025.01 ~ í˜„ì¬",
        "en": "Jan 2025 ~ Present"
      },
      "detail": {
        "problemSolving": [
          {
            "id": "async-migration",
            "title": {
              "ko": "ë™ì‹œì„± í”„ë¡œê·¸ë˜ë°: ë™ê¸°ì—ì„œ ë¹„ë™ê¸°ë¡œì˜ ëŒ€ì „í™˜",
              "en": "Concurrency Programming: Async/Await Migration"
            },
            "category": {
              "ko": "ë™ì‹œì„±",
              "en": "Concurrency"
            },
            "icon": "âš¡",
            "problem": {
              "ko": "**ì´ìŠˆ**: Redis í´ë¼ì´ì–¸íŠ¸ê°€ ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì‘ë™í•˜ì—¬ ë©€í‹°íŒŸ í™˜ê²½ì—ì„œ ë¸”ë¡œí‚¹ I/O ë°œìƒ. í•œ ìš”ì²­ì´ Redis ì‘ë‹µì„ ëŒ€ê¸°í•˜ëŠ” ë™ì•ˆ ë‹¤ë¥¸ ëª¨ë“  ìš”ì²­ì´ ëŒ€ê¸° ìƒíƒœë¡œ ì „í™˜ë˜ì–´ ì‘ë‹µ ì‹œê°„ì´ ê¸‰ê²©íˆ ì¦ê°€í•˜ê³  CPUê°€ ë‚­ë¹„ë˜ëŠ” ë¬¸ì œ.",
              "en": "**Issue**: Synchronous Redis client caused blocking I/O in multi-pod environment. While one request waited for Redis response, all other requests were blocked, causing response time spikes and CPU waste."
            },
            "solution": {
              "ko": "**í•´ê²°**: `redis-py` â†’ `aioredis`ë¡œ ì „ë©´ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ì—¬ ëª¨ë“  Redis ì‘ì—…ì„ `async/await` íŒ¨í„´ìœ¼ë¡œ ì „í™˜. Event Loop ê¸°ë°˜ ì•„í‚¤í…ì²˜ë¥¼ ë„ì…í•´ I/O ëŒ€ê¸° ì¤‘ì—ë„ ë‹¤ë¥¸ ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ê°œì„ . Background Log Workerë¥¼ ë¹„ë™ê¸°ë¡œ êµ¬í˜„í•˜ê³ , Lock Managerì— Context Manager íŒ¨í„´ì„ ì ìš©í•´ ìë™ í•´ì œ ë³´ì¥.",
              "en": "**Solution**: Migrated from `redis-py` to `aioredis`, converting all Redis operations to `async/await` pattern. Introduced event loop-based architecture to handle other requests during I/O waiting. Implemented asynchronous Background Log Worker and applied Context Manager pattern to Lock Manager for automatic release."
            },
            "technicalDetails": {
              "ko": "```python\n# Before (ë™ê¸°)\ndef deploy_agent(agent_id):\n    lock = redis.get(f\"lock:{agent_id}\")  # ë¸”ë¡œí‚¹ I/O\n    result = redis.set(f\"deployed:{agent_id}\", \"true\")\n    return result\n\n# After (ë¹„ë™ê¸°)\nasync def deploy_agent(agent_id):\n    lock = await redis.get(f\"lock:{agent_id}\")  # Non-blocking\n    # await ì¤‘ì— ë‹¤ë¥¸ ì½”ë£¨í‹´ ì‹¤í–‰ ê°€ëŠ¥\n    result = await redis.set(f\"deployed:{agent_id}\", \"true\")\n    return result\n```\n\n**í•µì‹¬ ë³€ê²½ì‚¬í•­**:\n- 13ê°œ íŒŒì¼ ìˆ˜ì •, +704ì¤„ / -338ì¤„\n- RedisClient ì „ë©´ ë¦¬íŒ©í† ë§\n- Event Loop ê¸°ë°˜ ì•„í‚¤í…ì²˜ êµ¬ì¶•\n- Distributed Lockì„ Non-blockingìœ¼ë¡œ ì „í™˜",
              "en": "```python\n# Before (sync)\ndef deploy_agent(agent_id):\n    lock = redis.get(f\"lock:{agent_id}\")  # Blocking I/O\n    result = redis.set(f\"deployed:{agent_id}\", \"true\")\n    return result\n\n# After (async)\nasync def deploy_agent(agent_id):\n    lock = await redis.get(f\"lock:{agent_id}\")  # Non-blocking\n    # Other coroutines can run during await\n    result = await redis.set(f\"deployed:{agent_id}\", \"true\")\n    return result\n```\n\n**Key Changes**:\n- 13 files modified, +704 / -338 lines\n- Complete RedisClient refactoring\n- Event loop-based architecture\n- Distributed Lock converted to non-blocking"
            },
            "csFoundations": [
              "Async/Await",
              "Event Loop",
              "Non-blocking I/O",
              "Cooperative Multitasking",
              "Concurrency vs Parallelism"
            ],
            "impact": {
              "ko": "**ì„±ê³¼**: ë©€í‹°íŒŸ í™˜ê²½ì—ì„œ ì‘ë‹µ ì‹œê°„ **40% ê°ì†Œ**. CPU í™œìš©ë¥  ê·¹ëŒ€í™”ë¡œ ë™ì‹œ ì²˜ë¦¬ ìš©ëŸ‰ ëŒ€í­ ì¦ê°€.",
              "en": "**Impact**: **40% reduction** in response time in multi-pod environment. Significantly increased concurrent processing capacity through maximized CPU utilization."
            },
            "commits": ["4b7a8aa"]
          },
          {
            "id": "race-condition",
            "title": {
              "ko": "ë¶„ì‚° ì‹œìŠ¤í…œ: Race Conditionê³¼ ë°ì´í„° ì¼ê´€ì„±",
              "en": "Distributed System: Race Condition Resolution"
            },
            "category": {
              "ko": "ë¶„ì‚°ì‹œìŠ¤í…œ",
              "en": "Distributed System"
            },
            "icon": "ğŸ”’",
            "problem": {
              "ko": "**ì´ìŠˆ**: ì—¬ëŸ¬ Podê°€ ë™ì‹œì— Agent ë²„ì „ ëª©ë¡ì„ ì½ê³  ìˆ˜ì •í•  ë•Œ Race Condition ë°œìƒ. Pod Aê°€ v3ë¥¼ ì¶”ê°€í•˜ëŠ” ë™ì•ˆ Pod Bê°€ ê°™ì€ ì‹œì ì— ì½ì–´ì„œ v4ë§Œ ì¶”ê°€í•˜ë©´, v3 ë°°í¬ê°€ ì†ì‹¤ë˜ëŠ” ì‹¬ê°í•œ ë°ì´í„° ë¬´ê²°ì„± ë¬¸ì œ.",
              "en": "**Issue**: Race condition occurred when multiple pods simultaneously read and modified agent version list. When Pod A added v3 while Pod B read at the same time and added only v4, v3 deployment was lost - a critical data integrity issue."
            },
            "solution": {
              "ko": "**í•´ê²°**: Redis ê¸°ë°˜ Distributed Lockì„ ë„ì…í•˜ì—¬ ì„ê³„ ì˜ì—­(Critical Section) ë³´í˜¸. Context Manager íŒ¨í„´(`async with`)ìœ¼ë¡œ Lock íšë“/í•´ì œë¥¼ ìë™í™”í•˜ê³ , íƒ€ì… ê²€ì¦ ë¡œì§ì„ ì¶”ê°€í•˜ì—¬ None/str/bytes ë“± ë‹¤ì–‘í•œ íƒ€ì…ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬. ë°˜í™˜ íƒ€ì…ì„ `set[str]`ë¡œ í†µì¼í•˜ì—¬ ì¼ê´€ì„± í™•ë³´.",
              "en": "**Solution**: Introduced Redis-based Distributed Lock to protect critical sections. Automated lock acquisition/release with Context Manager pattern (`async with`), added type validation logic to safely handle various types (None/str/bytes). Ensured consistency by unifying return type to `set[str]`."
            },
            "technicalDetails": {
              "ko": "```python\nasync def safe_deploy(agent_id, version):\n    async with RedisLock(f\"deploy:{agent_id}\") as lock:\n        # ì„ê³„ ì˜ì—­ ì‹œì‘ - í•œ ë²ˆì— í•˜ë‚˜ì˜ Podë§Œ ì§„ì…\n        versions = await redis.get(\"versions\")\n        \n        # íƒ€ì… ê²€ì¦ (None ì²´í¬ + íƒ€ì… ë³€í™˜)\n        if versions is None:\n            versions = set()\n        elif not isinstance(versions, set):\n            versions = set(versions) if versions else set()\n        \n        versions.add(version)\n        await redis.set(\"versions\", versions)\n        # ì„ê³„ ì˜ì—­ ë\n    \n    return versions\n```\n\n**í•µì‹¬ ê°œë…**: Mutual Exclusion (ìƒí˜¸ ë°°ì œ) + CAP ì´ë¡  ì ìš©",
              "en": "```python\nasync def safe_deploy(agent_id, version):\n    async with RedisLock(f\"deploy:{agent_id}\") as lock:\n        # Critical section - only one pod can enter\n        versions = await redis.get(\"versions\")\n        \n        # Type validation (None check + type conversion)\n        if versions is None:\n            versions = set()\n        elif not isinstance(versions, set):\n            versions = set(versions) if versions else set()\n        \n        versions.add(version)\n        await redis.set(\"versions\", versions)\n        # End of critical section\n    \n    return versions\n```\n\n**Core Concepts**: Mutual Exclusion + CAP Theorem"
            },
            "csFoundations": [
              "Distributed Lock",
              "Race Condition",
              "Mutual Exclusion",
              "CAP Theorem",
              "Type Safety"
            ],
            "impact": {
              "ko": "**ì„±ê³¼**: ë°°í¬ ì‹¤íŒ¨ìœ¨ **0%** ë‹¬ì„±. ë°ì´í„° ë¬´ê²°ì„± **100%** ë³´ì¥. ë©€í‹°íŒŸ í™˜ê²½ì—ì„œ ì™„ë²½í•œ ì¼ê´€ì„± í™•ë³´.",
              "en": "**Impact**: Achieved **0% deployment failure rate**. Guaranteed **100% data integrity**. Perfect consistency in multi-pod environment."
            },
            "commits": ["942909a", "76dfbc3"]
          },
          {
            "id": "memory-optimization",
            "title": {
              "ko": "ë©”ëª¨ë¦¬ ê´€ë¦¬: SSE ìŠ¤íŠ¸ë¦¬ë° ìµœì í™”",
              "en": "Memory Management: SSE Streaming Optimization"
            },
            "category": {
              "ko": "ë©”ëª¨ë¦¬ê´€ë¦¬",
              "en": "Memory Management"
            },
            "icon": "ğŸ’¾",
            "problem": {
              "ko": "**ì´ìŠˆ**: LLM í† í°ì„ SSEë¡œ ìŠ¤íŠ¸ë¦¬ë°í•  ë•Œ ëª¨ë“  í† í°ì„ ë¦¬ìŠ¤íŠ¸ì— ëˆ„ì  ì €ì¥í•˜ì—¬ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°œìƒ. ê¸´ ì‘ë‹µ(ìˆ˜ì²œ í† í°)ì˜ ê²½ìš° ìˆ˜ MB ë©”ëª¨ë¦¬ë¥¼ ì†Œë¹„í•˜ê³ , ë‹¤ìˆ˜ì˜ ë™ì‹œ ìš”ì²­ ì‹œ ì„œë²„ ë©”ëª¨ë¦¬ ê³ ê°ˆ ìœ„í—˜.",
              "en": "**Issue**: Memory leak occurred by accumulating all tokens in a list during LLM token streaming via SSE. Long responses (thousands of tokens) consumed several MB of memory, risking server memory exhaustion with multiple concurrent requests."
            },
            "solution": {
              "ko": "**í•´ê²°**: Generator íŒ¨í„´ìœ¼ë¡œ ì „í™˜í•˜ì—¬ Lazy Evaluation êµ¬í˜„. ê° í† í°ì„ yield ì¦‰ì‹œ GC(Garbage Collection) ëŒ€ìƒìœ¼ë¡œ ë§Œë“¤ì–´ ë©”ëª¨ë¦¬ì— ëˆ„ì ë˜ì§€ ì•Šë„ë¡ ê°œì„ . ë©”íƒ€ë°ì´í„°ëŠ” ì²˜ìŒ í•œ ë²ˆë§Œ ì „ì†¡í•˜ê³ , 1MB ë²„í¼ ì œí•œ ë° Stale Request ìë™ ì •ë¦¬ ë¡œì§ ì¶”ê°€.",
              "en": "**Solution**: Implemented Lazy Evaluation by switching to Generator pattern. Made each token eligible for GC (Garbage Collection) immediately after yield to prevent memory accumulation. Sent metadata only once at start, added 1MB buffer limit and automatic stale request cleanup logic."
            },
            "technicalDetails": {
              "ko": "```python\n# Before (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜)\ndef stream_tokens():\n    all_tokens = []  # ëª¨ë“  í† í°ì„ ë©”ëª¨ë¦¬ì— ì €ì¥!\n    for token in llm.generate():\n        all_tokens.append(token)\n        yield token\n    # all_tokensëŠ” ëê¹Œì§€ ë©”ëª¨ë¦¬ì— ë‚¨ìŒ\n\n# After (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )\nasync def stream_handler(request):\n    # ë©”íƒ€ë°ì´í„°ëŠ” í•œ ë²ˆë§Œ\n    yield {\"type\": \"metadata\", \"headers\": {...}}\n    \n    # í† í°ì€ í•˜ë‚˜ì”© yield (ë©”ëª¨ë¦¬ ì €ì¥ ì•ˆ í•¨)\n    async for token in llm.agenerate():\n        yield {\"type\": \"data\", \"content\": token}\n        # tokenì€ yield í›„ GC ëŒ€ìƒ\n```\n\n**í•µì‹¬**: Stream Processing (ë°°ì¹˜ ì²˜ë¦¬ ëŒ€ì‹  ì‹¤ì‹œê°„ ì²˜ë¦¬)",
              "en": "```python\n# Before (memory leak)\ndef stream_tokens():\n    all_tokens = []  # Stores all tokens in memory!\n    for token in llm.generate():\n        all_tokens.append(token)\n        yield token\n    # all_tokens remains in memory until end\n\n# After (memory efficient)\nasync def stream_handler(request):\n    # Metadata only once\n    yield {\"type\": \"metadata\", \"headers\": {...}}\n    \n    # Yield tokens one by one (no memory storage)\n    async for token in llm.agenerate():\n        yield {\"type\": \"data\", \"content\": token}\n        # token becomes GC target after yield\n```\n\n**Key**: Stream Processing (real-time instead of batch)"
            },
            "csFoundations": [
              "Generator Pattern",
              "Lazy Evaluation",
              "Garbage Collection",
              "Stream Processing",
              "Memory Management"
            ],
            "impact": {
              "ko": "**ì„±ê³¼**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ **70% ê°ì†Œ**. ì¥ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì—ì„œë„ ì•ˆì •ì ì¸ ë©”ëª¨ë¦¬ ìœ ì§€. ë™ì‹œ ì²˜ë¦¬ ê°€ëŠ¥ ìš”ì²­ ìˆ˜ ëŒ€í­ ì¦ê°€.",
              "en": "**Impact**: **70% reduction** in memory usage. Stable memory maintenance even during long-term streaming. Significantly increased concurrent request capacity."
            },
            "commits": ["346a8f5", "8c4aba6"]
          },
          {
            "id": "data-normalization",
            "title": {
              "ko": "ë°ì´í„° ì •ê·œí™”: Agent ID ë¶ˆì¼ì¹˜ í•´ê²°",
              "en": "Data Normalization: Agent ID Unification"
            },
            "category": {
              "ko": "ë°ì´í„°ì •ê·œí™”",
              "en": "Data Normalization"
            },
            "icon": "ğŸ¯",
            "problem": {
              "ko": "**ì´ìŠˆ**: ì‹œìŠ¤í…œ ì „ë°˜ì—ì„œ Agent ID í˜•ì‹ì´ ë¶ˆì¼ì¹˜('a123' vs '123')í•˜ì—¬ ê°™ì€ Agentë¥¼ ë‹¤ë¥¸ ê²ƒìœ¼ë¡œ ì¸ì‹. Frontend, Backend, Redis Eventì—ì„œ ê°ê° ë‹¤ë¥¸ í˜•ì‹ì„ ì‚¬ìš©í•´ Join ì—°ì‚° ì‹¤íŒ¨ ë° ì¤‘ë³µ ë°°í¬ ë°œìƒ.",
              "en": "**Issue**: Inconsistent Agent ID format across system ('a123' vs '123') caused same agent to be recognized as different. Different formats used in Frontend, Backend, and Redis Events led to join operation failures and duplicate deployments."
            },
            "solution": {
              "ko": "**í•´ê²°**: ì¤‘ì•™í™”ëœ `AgentIdNormalizer` í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í•˜ì—¬ ë‹¨ì¼ ì±…ì„ ì›ì¹™(SRP) ì ìš©. API Entry Pointì—ì„œ ì¦‰ì‹œ IDë¥¼ ì •ê·œí™”í•˜ê³ , ë‚´ë¶€ ë¡œì§ì€ ì •ê·œí™”ëœ IDë§Œ ì‚¬ìš©í•˜ë„ë¡ í†µì¼. Integer â†’ String ë³€í™˜ ë° ê³µë°± ì œê±° ë¡œì§ ì¶”ê°€.",
              "en": "**Solution**: Implemented centralized `AgentIdNormalizer` class applying Single Responsibility Principle (SRP). Normalized IDs immediately at API entry points, unified internal logic to use only normalized IDs. Added Integer â†’ String conversion and whitespace trimming logic."
            },
            "technicalDetails": {
              "ko": "```python\nclass AgentIdNormalizer:\n    @staticmethod\n    def normalize(agent_id: str) -> str:\n        \"\"\"ëª¨ë“  Agent IDë¥¼ ì¼ê´€ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\"\"\"\n        if agent_id.startswith('a'):\n            return agent_id[1:]  # 'a123' â†’ '123'\n        return agent_id\n    \n    @staticmethod\n    def with_prefix(agent_id: str) -> str:\n        \"\"\"í•„ìš”ì‹œ ì ‘ë‘ì‚¬ ì¶”ê°€\"\"\"\n        normalized = AgentIdNormalizer.normalize(agent_id)\n        return f\"a{normalized}\"\n\n# API ì§„ì…ì ì—ì„œ ì •ê·œí™”\n@app.post(\"/deploy\")\nasync def deploy(agent_id: str):\n    normalized_id = AgentIdNormalizer.normalize(agent_id)\n    # ì´í›„ ëª¨ë“  ë¡œì§ì€ normalized_id ì‚¬ìš©\n```\n\n**í•µì‹¬ ì›ì¹™**: Data Governance + Defensive Programming",
              "en": "```python\nclass AgentIdNormalizer:\n    @staticmethod\n    def normalize(agent_id: str) -> str:\n        \"\"\"Convert all Agent IDs to consistent format\"\"\"\n        if agent_id.startswith('a'):\n            return agent_id[1:]  # 'a123' â†’ '123'\n        return agent_id\n    \n    @staticmethod\n    def with_prefix(agent_id: str) -> str:\n        \"\"\"Add prefix if needed\"\"\"\n        normalized = AgentIdNormalizer.normalize(agent_id)\n        return f\"a{normalized}\"\n\n# Normalize at API entry point\n@app.post(\"/deploy\")\nasync def deploy(agent_id: str):\n    normalized_id = AgentIdNormalizer.normalize(agent_id)\n    # All subsequent logic uses normalized_id\n```\n\n**Core Principles**: Data Governance + Defensive Programming"
            },
            "csFoundations": [
              "Data Normalization",
              "Canonical Form",
              "Single Responsibility Principle",
              "Defensive Programming",
              "Input Validation"
            ],
            "impact": {
              "ko": "**ì„±ê³¼**: ID ê´€ë ¨ ë²„ê·¸ **0ê±´** ë‹¬ì„±. ì‹œìŠ¤í…œ ì „ë°˜ì˜ ë°ì´í„° ì¼ê´€ì„± í™•ë³´. ë””ë²„ê¹… ì‹œê°„ ëŒ€í­ ë‹¨ì¶•.",
              "en": "**Impact**: Achieved **0 ID-related bugs**. Ensured data consistency across entire system. Significantly reduced debugging time."
            },
            "commits": ["5f21d96", "da0d614"]
          }
        ],
        "architecture": [
          {
            "title": {
              "ko": "PyRunner ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜",
              "en": "PyRunner System Architecture"
            },
            "description": {
              "ko": "Multi-Process FastAPI ì„œë²„ì™€ Redis ê¸°ë°˜ ë¶„ì‚° ë™ê¸°í™” êµ¬ì¡°. ì‚¬ìš©ì ì½”ë“œë¥¼ ë™ì  Sub-Appìœ¼ë¡œ ë¡œë”©í•˜ì—¬ ë…ë¦½ì„±ì„ ë³´ì¥í•˜ë©°, Pub/Subì„ í†µí•´ ë¬´ì¤‘ë‹¨ ë°°í¬ë¥¼ ì‹¤í˜„í•©ë‹ˆë‹¤.",
              "en": "Multi-process FastAPI server with Redis-based distributed synchronization. Dynamically loads user code as isolated Sub-Apps and enables zero-downtime deployment via Pub/Sub."
            },
            "mermaidFilePath": {
              "ko": "/architecture/pyrunner/system-architecture.mmd",
              "en": "/architecture/pyrunner/system-architecture-en.mmd"
            }
          },
          {
            "title": {
              "ko": "Race Condition í•´ê²° ê³¼ì •",
              "en": "Race Condition Resolution"
            },
            "description": {
              "ko": "íŒŒì¼ ì‹œìŠ¤í…œ ì§ì ‘ ê°ì§€ ë°©ì‹ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ Redis Distributed Lockì„ ë„ì…. ë°°í¬ ì‹¤íŒ¨ìœ¨ 0%ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.",
              "en": "Overcame filesystem monitoring limitations by introducing Redis Distributed Lock, achieving 0% deployment failure rate."
            },
            "mermaidFilePath": {
              "ko": "/architecture/pyrunner/race-condition-resolution.mmd",
              "en": "/architecture/pyrunner/race-condition-resolution-en.mmd"
            }
          }
        ]
      },
      "featured": true,
      "order": 1
    },
    {
      "id": "log-collector",
      "title": "Log Collector",
      "shortDescription": {
        "ko": "At-least-once ë³´ì¥ ë¶„ì‚° ë¡œê·¸ ìˆ˜ì§‘ ì‹œìŠ¤í…œ",
        "en": "At-least-once Guaranteed Distributed Log Collection System"
      },
      "fullDescription": {
        "ko": "Redis Stream Consumer Group ê¸°ë°˜ ë¡œê·¸ ìˆ˜ì§‘ ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ì…ë‹ˆë‹¤. ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì´ˆë‹¹ ìˆ˜ë°± ê±´ì˜ ë¡œê·¸ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©°, ì¥ì•  ì‹œì—ë„ ë¡œê·¸ ì†ì‹¤ ì—†ì´ At-least-once ì „ë‹¬ì„ ë³´ì¥í•©ë‹ˆë‹¤.",
        "en": "Background worker for log collection based on Redis Stream Consumer Group. Efficiently processes hundreds of logs per second through batch processing, ensuring at-least-once delivery without log loss even during failures."
      },
      "techStack": [
        "Python 3.11",
        "asyncio",
        "Redis Stream",
        "Consumer Group",
        "httpx",
        "Pydantic"
      ],
      "keyAchievements": [
        {
          "ko": "ë°°ì¹˜ ì²˜ë¦¬ë¡œ HTTP í˜¸ì¶œ 99% ê°ì†Œ (1ê±´ë‹¹ 2íšŒ â†’ ë°°ì¹˜ë‹¹ 2íšŒ)",
          "en": "99% reduction in HTTP calls through batch processing (2 per log â†’ 2 per batch)"
        },
        {
          "ko": "At-least-once ì „ë‹¬ ë³´ì¥ (flush ì„±ê³µ í›„ì—ë§Œ ACK)",
          "en": "At-least-once delivery guarantee (ACK only after successful flush)"
        },
        {
          "ko": "ì¤‘ë³µ ì œê±° & ì‹œê°„ìˆœ ì •ë ¬ë¡œ ì¬ì „ë‹¬ ë¡œê·¸ ìë™ ì²˜ë¦¬",
          "en": "Automatic handling of redelivered logs via deduplication & time-based sorting"
        },
        {
          "ko": "Sidecar íŒ¨í„´ìœ¼ë¡œ PyEditorì™€ í•¨ê»˜ ë°°í¬ (~50MB ë©”ëª¨ë¦¬)",
          "en": "Sidecar pattern deployment with PyEditor (~50MB memory)"
        }
      ],
      "features": [
        "Redis Consumer Group",
        "Batch Processing",
        "At-least-once Delivery",
        "Graceful Shutdown",
        "Time-based Sorting"
      ],
      "repoPath": "log-collector",
      "company": {
        "ko": "(ì£¼)í¬ì§€íë¸Œ",
        "en": "Posicube Inc."
      },
      "period": {
        "ko": "2024.12 ~ í˜„ì¬",
        "en": "Dec 2024 ~ Present"
      },
      "detail": {
        "problemSolving": [
          {
            "id": "batch-processing",
            "title": {
              "ko": "ë°°ì¹˜ ì²˜ë¦¬: HTTP ì˜¤ë²„í—¤ë“œ 99% ê°ì†Œ",
              "en": "Batch Processing: 99% HTTP Overhead Reduction"
            },
            "category": {
              "ko": "ì„±ëŠ¥ìµœì í™”",
              "en": "Performance"
            },
            "icon": "ğŸš€",
            "problem": {
              "ko": "**ì´ìŠˆ**: ë¡œê·¸ 1ê±´ë‹¹ HTTP í˜¸ì¶œ 2íšŒ(GET+POST) í•„ìš”. ì´ˆë‹¹ 100ê±´ ë¡œê·¸ ë°œìƒ ì‹œ 200íšŒ HTTP í˜¸ì¶œë¡œ ë„¤íŠ¸ì›Œí¬ ë³‘ëª© ë°œìƒ. ê° HTTP í˜¸ì¶œì˜ ê³ ì • ë¹„ìš©(~50ms)ìœ¼ë¡œ ì¸í•´ ì²˜ë¦¬ëŸ‰ì´ ì´ˆë‹¹ 10ê±´ì— ë¶ˆê³¼.",
              "en": "**Issue**: Each log required 2 HTTP calls (GET+POST). With 100 logs/second, 200 HTTP calls caused network bottleneck. Fixed cost per HTTP call (~50ms) limited throughput to only 10 logs/second."
            },
            "solution": {
              "ko": "**í•´ê²°**: 1ì´ˆ ì£¼ê¸° ë°°ì¹˜ ì²˜ë¦¬ ë„ì…. ë¡œê·¸ë¥¼ ë©”ëª¨ë¦¬ ë²„í¼ì— ì¶•ì  í›„ í•œ ë²ˆì— ì „ì†¡í•˜ì—¬ HTTP í˜¸ì¶œì„ 2íšŒë¡œ í†µí•©. ì—ì´ì „íŠ¸ë³„ ë²„í¼ ê´€ë¦¬ë¡œ ë…ë¦½ì„± ë³´ì¥.",
              "en": "**Solution**: Introduced 1-second interval batch processing. Accumulated logs in memory buffer then sent at once, consolidating HTTP calls to just 2. Maintained independence through per-agent buffer management."
            },
            "technicalDetails": {
              "ko": "```python\n# Before (ê±´ë‹¹ ì²˜ë¦¬)\nfor log in logs:  # 100ê°œ\n    await client.get(url)   # 50ms Ã— 100\n    await client.post(url)  # 50ms Ã— 100\n# ì´ ì‹œê°„: 10,000ms (10ì´ˆ)\n\n# After (ë°°ì¹˜ ì²˜ë¦¬)\nbuffer.extend(logs)  # ë²„í¼ì— ì¶•ì \nawait asyncio.sleep(1)  # 1ì´ˆ ëŒ€ê¸°\n\n# í•œ ë²ˆì— ì²˜ë¦¬\ncombined = '\\n'.join(buffer)\nawait client.get(url)   # 50ms Ã— 1\nawait client.post(url)  # 50ms Ã— 1\n# ì´ ì‹œê°„: ~1,100ms\n```\n\n**í•µì‹¬**: ë„¤íŠ¸ì›Œí¬ ì™•ë³µ íšŸìˆ˜ ìµœì†Œí™”",
              "en": "```python\n# Before (per-log)\nfor log in logs:  # 100 logs\n    await client.get(url)   # 50ms Ã— 100\n    await client.post(url)  # 50ms Ã— 100\n# Total: 10,000ms (10 seconds)\n\n# After (batch)\nbuffer.extend(logs)  # Accumulate\nawait asyncio.sleep(1)  # Wait 1 sec\n\n# Process at once\ncombined = '\\n'.join(buffer)\nawait client.get(url)   # 50ms Ã— 1\nawait client.post(url)  # 50ms Ã— 1\n# Total: ~1,100ms\n```\n\n**Key**: Minimize network round-trips"
            },
            "csFoundations": [
              "Batch Processing",
              "Buffer Management",
              "Amortized Cost",
              "I/O Optimization"
            ],
            "impact": {
              "ko": "**ì„±ê³¼**: HTTP í˜¸ì¶œ íšŸìˆ˜ **99% ê°ì†Œ** (200íšŒ â†’ 2íšŒ). ì²˜ë¦¬ëŸ‰ **10ë°° ì´ìƒ í–¥ìƒ** (ì´ˆë‹¹ 10ê±´ â†’ ìˆ˜ë°± ê±´).",
              "en": "**Impact**: HTTP calls reduced by **99%** (200 â†’ 2). Throughput improved by **10x+** (10/sec â†’ hundreds/sec)."
            },
            "commits": []
          },
          {
            "id": "at-least-once",
            "title": {
              "ko": "At-least-once: ì¥ì• ì—ë„ ë¡œê·¸ ì†ì‹¤ ì œë¡œ",
              "en": "At-least-once: Zero Log Loss Even During Failures"
            },
            "category": {
              "ko": "ë¶„ì‚°ì‹œìŠ¤í…œ",
              "en": "Distributed System"
            },
            "icon": "ğŸ›¡ï¸",
            "problem": {
              "ko": "**ì´ìŠˆ**: ê¸°ì¡´ ë°©ì‹ì€ ë©”ì‹œì§€ ìˆ˜ì‹  ì¦‰ì‹œ ACK ì²˜ë¦¬. ë²„í¼ì— ë¡œê·¸ê°€ ìˆëŠ” ìƒíƒœì—ì„œ ì„œë²„ ì¥ì•  ì‹œ í•´ë‹¹ ë¡œê·¸ ì˜êµ¬ ì†ì‹¤. Redisì—ì„œ ì´ë¯¸ ACKëœ ë©”ì‹œì§€ëŠ” ì¬ì „ë‹¬ë˜ì§€ ì•ŠìŒ.",
              "en": "**Issue**: Previous approach ACKed messages immediately upon receipt. If server crashed with logs in buffer, those logs were permanently lost. Redis doesn't redeliver already-ACKed messages."
            },
            "solution": {
              "ko": "**í•´ê²°**: ACKë¥¼ flush ì„±ê³µ í›„ì—ë§Œ ìˆ˜í–‰í•˜ë„ë¡ ë³€ê²½. ì‹¤íŒ¨ ì‹œ ë²„í¼ì— ë¡œê·¸ë¥¼ ë‹¤ì‹œ ë„£ì–´ ë‹¤ìŒ ì£¼ê¸°ì— ì¬ì‹œë„. ì„œë²„ ì¥ì•  ì‹œ Redis Consumer Groupì´ ë§ˆì§€ë§‰ ACK ì§€ì ë¶€í„° ì¬ì „ë‹¬.",
              "en": "**Solution**: Changed to ACK only after successful flush. On failure, put logs back in buffer for retry in next cycle. On server crash, Redis Consumer Group redelivers from last ACK point."
            },
            "technicalDetails": {
              "ko": "```python\nasync def _flush_agent(self, agent_key):\n    logs = self.buffer.pop(agent_key, [])\n    \n    try:\n        await self._write_batch(logs)\n        \n        # ì„±ê³µ ì‹œì—ë§Œ ACK\n        for log in logs:\n            await self.ack_callback(log.msg_id)\n            \n    except Exception:\n        # ì‹¤íŒ¨ ì‹œ ë²„í¼ì— ë°˜í™˜\n        self.buffer[agent_key] = logs\n```\n\n**í•µì‹¬**: ACK ì§€ì—° + ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ = At-least-once",
              "en": "```python\nasync def _flush_agent(self, agent_key):\n    logs = self.buffer.pop(agent_key, [])\n    \n    try:\n        await self._write_batch(logs)\n        \n        # ACK only on success\n        for log in logs:\n            await self.ack_callback(log.msg_id)\n            \n    except Exception:\n        # On failure, return to buffer\n        self.buffer[agent_key] = logs\n```\n\n**Key**: Delayed ACK + retry on failure = At-least-once"
            },
            "csFoundations": [
              "At-least-once Delivery",
              "Consumer Group",
              "Message Acknowledgment",
              "Failure Recovery"
            ],
            "impact": {
              "ko": "**ì„±ê³¼**: ì¥ì•  ì‹œ ë¡œê·¸ ì†ì‹¤ **ì œë¡œ**. ì„œë²„ ì¬ì‹œì‘ í›„ ìë™ ë³µêµ¬. ë°ì´í„° ì‹ ë¢°ì„± **100%** ë³´ì¥.",
              "en": "**Impact**: **Zero** log loss during failures. Automatic recovery after server restart. **100%** data reliability guaranteed."
            },
            "commits": []
          },
          {
            "id": "dedup-sorting",
            "title": {
              "ko": "ì¤‘ë³µ ì œê±° & ì‹œê°„ìˆœ ì •ë ¬: ì¬ì „ë‹¬ ë¡œê·¸ ì²˜ë¦¬",
              "en": "Deduplication & Sorting: Handling Redelivered Logs"
            },
            "category": {
              "ko": "ë°ì´í„°ê´€ë¦¬",
              "en": "Data Management"
            },
            "icon": "ğŸ”„",
            "problem": {
              "ko": "**ì´ìŠˆ**: At-least-once ë°©ì‹ì€ ì¬ì „ë‹¬ë¡œ ì¸í•œ ì¤‘ë³µ ë¡œê·¸ ë°œìƒ ê°€ëŠ¥. ë˜í•œ ë¹„ë™ê¸° ì²˜ë¦¬ë¡œ ë¡œê·¸ ìˆœì„œê°€ ë’¤ì„ì¼ ìˆ˜ ìˆì–´ ë””ë²„ê¹… ì‹œ ì‹œê°„ìˆœ ì¶”ì ì´ ì–´ë ¤ì›€.",
              "en": "**Issue**: At-least-once delivery can cause duplicate logs due to redelivery. Also, async processing can scramble log order, making time-based debugging difficult."
            },
            "solution": {
              "ko": "**í•´ê²°**: PyEditorì— ì“°ê¸° ì „ ì¤‘ë³µ ì œê±°(dict.fromkeysë¡œ ìˆœì„œ ìœ ì§€) ë° íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ ì •ë ¬ ì ìš©. ë¡œê·¸ í¬ë§· `[date][time]...`ì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œí•˜ì—¬ ì •ë ¬.",
              "en": "**Solution**: Applied deduplication (dict.fromkeys preserves order) and timestamp-based sorting before writing to PyEditor. Extracted timestamp from log format `[date][time]...` for sorting."
            },
            "technicalDetails": {
              "ko": "```python\ndef _write_batch(self, logs):\n    new_lines = [log.format() for log in logs]\n    all_lines = existing_lines + new_lines\n    \n    # ì¤‘ë³µ ì œê±° (ìˆœì„œ ìœ ì§€)\n    unique = list(dict.fromkeys(all_lines))\n    \n    # ì‹œê°„ìˆœ ì •ë ¬\n    unique.sort(key=self._extract_timestamp)\n    return unique\n```\n\n**í•µì‹¬**: Idempotent Write (ë©±ë“± ì“°ê¸°)",
              "en": "```python\ndef _write_batch(self, logs):\n    new_lines = [log.format() for log in logs]\n    all_lines = existing_lines + new_lines\n    \n    # Deduplicate (preserve order)\n    unique = list(dict.fromkeys(all_lines))\n    \n    # Sort by time\n    unique.sort(key=self._extract_timestamp)\n    return unique\n```\n\n**Key**: Idempotent Write"
            },
            "csFoundations": [
              "Idempotency",
              "Deduplication",
              "Sorting Algorithm",
              "Data Integrity"
            ],
            "impact": {
              "ko": "**ì„±ê³¼**: ì¤‘ë³µ ë¡œê·¸ **ìë™ ì œê±°**. ì‹œê°„ìˆœ ì •ë ¬ë¡œ ë””ë²„ê¹… íš¨ìœ¨ì„± **í–¥ìƒ**. ë¡œê·¸ í’ˆì§ˆ **100%** ë³´ì¥.",
              "en": "**Impact**: Duplicate logs **automatically removed**. Debugging efficiency **improved** with time-sorted logs. **100%** log quality guaranteed."
            },
            "commits": []
          }
        ],
        "architecture": [
          {
            "title": {
              "ko": "ë°°ì¹˜ ì²˜ë¦¬ í”Œë¡œìš°",
              "en": "Batch Processing Flow"
            },
            "description": {
              "ko": "Redis Streamì—ì„œ PyEditorê¹Œì§€ì˜ At-least-once ë°°ì¹˜ ì²˜ë¦¬ í”Œë¡œìš°. ë©”ì‹œì§€ ìˆ˜ì‹ , ë²„í¼ ì¶•ì , flush, ACKì˜ ì „ì²´ ê³¼ì •ê³¼ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜.",
              "en": "At-least-once batch processing flow from Redis Stream to PyEditor. Complete process of message reception, buffer accumulation, flush, ACK, and retry mechanism on failure."
            },
            "mermaidFilePath": {
              "ko": "/architecture/log-collector/batch-flow.mmd",
              "en": "/architecture/log-collector/batch-flow-en.mmd"
            }
          }
        ]
      },
      "featured": false,
      "order": 4
    },
    {
      "id": "opic-master",
      "title": "OPIc Master",
      "shortDescription": {
        "ko": "AI ê¸°ë°˜ OPIc ì‹¤ì „ ëª¨ì˜ê³ ì‚¬ & í”¼ë“œë°± ì•±",
        "en": "AI-Powered OPIc Mock Test & Feedback App"
      },
      "fullDescription": {
        "ko": "Google Play/App Store ì¶œì‹œëœ í¬ë¡œìŠ¤í”Œë«í¼ OPIc í•™ìŠµ ì•±ì…ë‹ˆë‹¤. Gemini AI ê¸°ë°˜ ì‹¤ì‹œê°„ ìŒì„± ë¶„ì„ìœ¼ë¡œ ë¬¸ë²•/ë°œìŒ/ìœ ì°½ì„± í”¼ë“œë°±ì„ ì œê³µí•˜ê³ , SRS(ê°„ê²©ë°˜ë³µ) í•™ìŠµ ì‹œìŠ¤í…œê³¼ êµ¬ì¡°í™”ëœ ëª¨ë²” ë‹µì•ˆ ì‰ë„ì‰ ê¸°ëŠ¥ì„ í†µí•´ íš¨ê³¼ì ì¸ OPIc ì¤€ë¹„ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.",
        "en": "Cross-platform OPIc learning app published on Google Play/App Store. Provides real-time grammar/pronunciation/fluency feedback through Gemini AI-based voice analysis, with SRS flashcard system and structured model answer shadowing for effective OPIc preparation."
      },
      "techStack": [
        "Next.js 16",
        "React 19",
        "Capacitor",
        "TypeScript",
        "Prisma",
        "Gemini AI",
        "TossPayments"
      ],
      "keyAchievements": [
        {
          "ko": "Google Play/App Store ë™ì‹œ ì¶œì‹œ (Web + iOS + Android)",
          "en": "Published on both Google Play & App Store (Web + iOS + Android)"
        },
        {
          "ko": "Gemini AI ê¸°ë°˜ ì‹¤ì‹œê°„ STT ë¶„ì„ & 5ê°œ ì˜ì—­ í”¼ë“œë°± (ë¬¸ë²•/ì–´íœ˜/ë°œìŒ/ìœ ì°½ì„±/ë‚´ìš©)",
          "en": "Real-time STT analysis & 5-domain feedback with Gemini AI (Grammar/Vocabulary/Pronunciation/Fluency/Content)"
        },
        {
          "ko": "ì¸ë¼ì¸ ë¬¸ë²• êµì • UI (íƒ­í•˜ì—¬ ìˆ˜ì • ë‚´ìš© í™•ì¸)",
          "en": "Inline grammar correction UI (tap to view fix details)"
        },
        {
          "ko": "SRS(ê°„ê²©ë°˜ë³µ) ê¸°ë°˜ í‘œí˜„ í•™ìŠµ ì‹œìŠ¤í…œ",
          "en": "SRS-based expression learning system"
        },
        {
          "ko": "êµ¬ì¡°í™”ëœ ëª¨ë²” ë‹µì•ˆ ì‰ë„ì‰ (OPIc í…œí”Œë¦¿ í•™ìŠµ)",
          "en": "Structured model answer shadowing (OPIc template learning)"
        }
      ],
      "features": [
        "Real-time AI Feedback",
        "Cross-platform (Capacitor)",
        "SRS Flashcards",
        "Inline Grammar Correction",
        "Structured Shadowing"
      ],
      "repoPath": "opic-master",
      "platformLinks": {
        "web": "https://opic.po24lio.com",
        "ios": "https://apps.apple.com/kr/app/%EC%98%A4%ED%94%BD-%EB%A7%88%EC%8A%A4%ED%84%B0/id6757357743",
        "android": "https://play.google.com/store/apps/details?id=com.ruiboss.opic"
      },
      "company": {
        "ko": "ê°œì¸ í”„ë¡œì íŠ¸ (ë£¨ì´ë³´ìŠ¤)",
        "en": "Personal Project (Rooibos)"
      },
      "period": {
        "ko": "2025.12 ~ í˜„ì¬",
        "en": "Dec 2025 ~ Present"
      },
      "detail": {
        "problemSolving": [
          {
            "id": "inline-grammar-correction",
            "title": {
              "ko": "ì¸ë¼ì¸ ë¬¸ë²• êµì •: ì§ê´€ì  í”¼ë“œë°± UX",
              "en": "Inline Grammar Correction: Intuitive Feedback UX"
            },
            "category": {
              "ko": "UXì„¤ê³„",
              "en": "UX Design"
            },
            "icon": "âœï¸",
            "problem": {
              "ko": "**ì´ìŠˆ**: ë¬¸ë²• ì˜¤ë¥˜ë¥¼ ë³„ë„ ì„¹ì…˜ì— ë¦¬ìŠ¤íŠ¸ë¡œ í‘œì‹œí•˜ë©´ ì‚¬ìš©ìê°€ ìì‹ ì˜ ë‹µë³€ì—ì„œ ì–´ë””ê°€ í‹€ë ¸ëŠ”ì§€ ì°¾ê¸° ì–´ë ¤ì›€. íŒì˜¤ë²„ ë°©ì‹ì€ ëª¨ë°”ì¼ì—ì„œ ì‚¬ìš©ì„±ì´ ë–¨ì–´ì§€ê³ , ì •ì  diffëŠ” UIê°€ ë³µì¡í•´ì§€ëŠ” ë¬¸ì œ.",
              "en": "**Issue**: Displaying grammar errors as a separate list made it difficult for users to locate errors in their answers. Popovers were unreliable on mobile, and static diffs cluttered the UI."
            },
            "solution": {
              "ko": "**í•´ê²°**: ì¸ë¼ì¸ í™•ì¥í˜• ì•„ì½”ë””ì–¸ íŒ¨í„´ ë„ì…. í‹€ë¦° í‘œí˜„ì— ë°‘ì¤„ì„ í‘œì‹œí•˜ê³ , íƒ­í•˜ë©´ í•´ë‹¹ ìœ„ì¹˜ì—ì„œ ë°”ë¡œ ìˆ˜ì • ë‚´ìš©ê³¼ ì„¤ëª…ì´ í¼ì³ì§€ëŠ” UX. í…ìŠ¤íŠ¸ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ AI ì¸ë±ìŠ¤ ì˜¤ë¥˜ì—ë„ ì•ˆì •ì ìœ¼ë¡œ í•˜ì´ë¼ì´íŠ¸ í‘œì‹œ.",
              "en": "**Solution**: Introduced inline-expandable accordion pattern. Underlined incorrect phrases that expand correction details on tap. Implemented text-matching algorithm for reliable highlighting even with AI index errors."
            },
            "technicalDetails": {
              "ko": "```tsx\n// ì¸ë¼ì¸ í™•ì¥ íŒ¨í„´\n<span className={styles.correctionWrapper}>\n  <span \n    className={`${styles.originalText} ${isExpanded ? styles.expanded : ''}`}\n    onClick={() => toggleExpand(idx)}\n  >\n    {original}\n  </span>\n  {isExpanded && (\n    <span className={styles.correctionDetail}>\n      <span className={styles.arrow}>â†’</span>\n      <span className={styles.correctedText}>{corrected}</span>\n      {explanation && <span className={styles.explanation}>{explanation}</span>}\n    </span>\n  )}\n</span>\n```\n\n**í•µì‹¬**: Case-insensitive í…ìŠ¤íŠ¸ ë§¤ì¹­ìœ¼ë¡œ ì•ˆì •ì„± í™•ë³´",
              "en": "```tsx\n// Inline expansion pattern\n<span className={styles.correctionWrapper}>\n  <span \n    className={`${styles.originalText} ${isExpanded ? styles.expanded : ''}`}\n    onClick={() => toggleExpand(idx)}\n  >\n    {original}\n  </span>\n  {isExpanded && (\n    <span className={styles.correctionDetail}>\n      <span className={styles.arrow}>â†’</span>\n      <span className={styles.correctedText}>{corrected}</span>\n      {explanation && <span className={styles.explanation}>{explanation}</span>}\n    </span>\n  )}\n</span>\n```\n\n**Key**: Case-insensitive text matching for reliability"
            },
            "csFoundations": [
              "Progressive Disclosure",
              "Text Matching Algorithm",
              "Accessible UI",
              "Mobile-first Design"
            ],
            "impact": {
              "ko": "**ì„±ê³¼**: ë¬¸ë²• í”¼ë“œë°± ì‚¬ìš©ì„± **ëŒ€í­ ê°œì„ **. ëª¨ë°”ì¼ í„°ì¹˜ UX ìµœì í™”. íŒì˜¤ë²„ ëŒ€ë¹„ **ì•ˆì •ì„± 100%**.",
              "en": "**Impact**: Grammar feedback usability **significantly improved**. Optimized mobile touch UX. **100% reliability** compared to popovers."
            },
            "commits": []
          },
          {
            "id": "srs-flashcard-system",
            "title": {
              "ko": "SRS ê°„ê²©ë°˜ë³µ í•™ìŠµ ì‹œìŠ¤í…œ",
              "en": "SRS Spaced Repetition System"
            },
            "category": {
              "ko": "í•™ìŠµì•Œê³ ë¦¬ì¦˜",
              "en": "Learning Algorithm"
            },
            "icon": "ğŸ§ ",
            "problem": {
              "ko": "**ì´ìŠˆ**: ë‹¨ìˆœ í”Œë˜ì‹œì¹´ë“œ í•™ìŠµì€ íš¨ìœ¨ì´ ë–¨ì–´ì§€ê³ , ì‚¬ìš©ìê°€ ë³µìŠµ ì‹œì ì„ ì§ì ‘ ê´€ë¦¬í•˜ê¸° ì–´ë ¤ì›€. í•™ìŠµ ì™„ë£Œ í›„ 'ë§‰ë‹¤ë¥¸ ê¸¸' ëŠë‚Œìœ¼ë¡œ ì´íƒˆ ë°œìƒ.",
              "en": "**Issue**: Simple flashcard learning was inefficient, and users struggled to manage review timing. Post-completion 'dead end' feeling caused user drop-off."
            },
            "solution": {
              "ko": "**í•´ê²°**: SM-2 ê¸°ë°˜ SRS ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„. ì •ë‹µ/ì˜¤ë‹µì— ë”°ë¼ ë‹¤ìŒ ë³µìŠµ ê°„ê²©ì„ ìë™ ì¡°ì ˆí•˜ê³ , 'Due Cards' ì¹´ìš´í„°ë¡œ ë³µìŠµ í•„ìš” ì¹´ë“œë¥¼ ì‹¤ì‹œê°„ í‘œì‹œ. ì™„ë£Œ í™”ë©´ì—ì„œ 'ìƒˆ í•™ìŠµ'/'ë³µìŠµ' ë¶„ê¸°ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì œê³µ.",
              "en": "**Solution**: Implemented SM-2 based SRS algorithm. Auto-adjusts next review interval based on correct/incorrect answers. Displays 'Due Cards' counter in real-time. Provides explicit 'New Learning'/'Review' branching on completion screen."
            },
            "technicalDetails": {
              "ko": "```typescript\n// SRS ê°„ê²© ê³„ì‚°\nfunction calculateNextReview(card: Card, quality: number) {\n  const { easeFactor, interval, repetitions } = card;\n  \n  if (quality >= 3) { // ì •ë‹µ\n    const newInterval = repetitions === 0 ? 1 \n      : repetitions === 1 ? 6 \n      : Math.round(interval * easeFactor);\n    return {\n      interval: newInterval,\n      repetitions: repetitions + 1,\n      easeFactor: Math.max(1.3, easeFactor + 0.1 - (5 - quality) * 0.08)\n    };\n  } else { // ì˜¤ë‹µ\n    return { interval: 1, repetitions: 0, easeFactor };\n  }\n}\n```\n\n**í•µì‹¬**: SM-2 ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ë§ê° ê³¡ì„  ìµœì í™”",
              "en": "```typescript\n// SRS interval calculation\nfunction calculateNextReview(card: Card, quality: number) {\n  const { easeFactor, interval, repetitions } = card;\n  \n  if (quality >= 3) { // Correct\n    const newInterval = repetitions === 0 ? 1 \n      : repetitions === 1 ? 6 \n      : Math.round(interval * easeFactor);\n    return {\n      interval: newInterval,\n      repetitions: repetitions + 1,\n      easeFactor: Math.max(1.3, easeFactor + 0.1 - (5 - quality) * 0.08)\n    };\n  } else { // Incorrect\n    return { interval: 1, repetitions: 0, easeFactor };\n  }\n}\n```\n\n**Key**: SM-2 algorithm optimizing forgetting curve"
            },
            "csFoundations": [
              "Spaced Repetition",
              "SM-2 Algorithm",
              "Learning Science",
              "State Machine"
            ],
            "impact": {
              "ko": "**ì„±ê³¼**: í•™ìŠµ íš¨ìœ¨ **í–¥ìƒ**. ì‚¬ìš©ì ì´íƒˆë¥  **ê°ì†Œ**. ë³µìŠµ íƒ€ì´ë° ìë™í™”ë¡œ UX ê°œì„ .",
              "en": "**Impact**: Learning efficiency **improved**. User drop-off **reduced**. Automated review timing enhanced UX."
            },
            "commits": []
          },
          {
            "id": "cross-platform-iap",
            "title": {
              "ko": "í¬ë¡œìŠ¤í”Œë«í¼ ì¸ì•±ê²°ì œ í†µí•©",
              "en": "Cross-platform In-App Purchase Integration"
            },
            "category": {
              "ko": "ê²°ì œ",
              "en": "Payments"
            },
            "icon": "ï¿½",
            "problem": {
              "ko": "**ì´ìŠˆ**: Webì€ TossPayments, iOSëŠ” App Store IAP, AndroidëŠ” Google Play Billingìœ¼ë¡œ ê²°ì œ ì‹œìŠ¤í…œì´ ì™„ì „íˆ ë¶„ë¦¬. ê° í”Œë«í¼ë³„ ì˜ìˆ˜ì¦ ê²€ì¦ ë¡œì§ í•„ìš”. í™˜ë¶ˆ ì²˜ë¦¬ ì‹œ í”„ë¦¬ë¯¸ì—„ ê¶Œí•œ ë™ê¸°í™” ë¬¸ì œ.",
              "en": "**Issue**: Completely separate payment systems - Web (TossPayments), iOS (App Store IAP), Android (Google Play Billing). Each platform required different receipt verification logic. Premium access sync issues during refunds."
            },
            "solution": {
              "ko": "**í•´ê²°**: í”Œë«í¼ë³„ ì „ìš© ê²°ì œ API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„. Google/Apple ì„œë²„ì‚¬ì´ë“œ ì˜ìˆ˜ì¦ ê²€ì¦ ë¡œì§ êµ¬ì¶•. Webhookìœ¼ë¡œ í™˜ë¶ˆ ì´ë²¤íŠ¸ ìˆ˜ì‹ í•˜ì—¬ í”„ë¦¬ë¯¸ì—„ ê¶Œí•œ ì¦‰ì‹œ ì·¨ì†Œ. ê²°ì œ ìƒíƒœë¥¼ DBì—ì„œ í†µí•© ê´€ë¦¬.",
              "en": "**Solution**: Implemented platform-specific payment API endpoints. Built server-side receipt verification for Google/Apple. Received refund events via webhooks to immediately revoke premium access. Unified payment status management in DB."
            },
            "technicalDetails": {
              "ko": "```typescript\n// Google Play ì˜ìˆ˜ì¦ ê²€ì¦ API\nexport async function POST(request: Request) {\n  const { purchaseToken, productId } = await request.json();\n  \n  // 1. Google Play APIë¡œ ì˜ìˆ˜ì¦ ê²€ì¦\n  const auth = new GoogleAuth({ credentials });\n  const client = await auth.getClient();\n  const response = await client.request({\n    url: `https://androidpublisher.googleapis.com/...`,\n    method: 'GET'\n  });\n  \n  // 2. ê²°ì œ ìƒíƒœ í™•ì¸\n  if (response.data.purchaseState !== 0) {\n    throw new Error('Invalid purchase');\n  }\n  \n  // 3. DBì— ê²°ì œ ê¸°ë¡ & í”„ë¦¬ë¯¸ì—„ ê¶Œí•œ ë¶€ì—¬\n  await prisma.user.update({\n    where: { id: userId },\n    data: { tier: 'PREMIUM', premiumExpiresAt }\n  });\n}\n```\n\n**í•µì‹¬**: í”Œë«í¼ë³„ ì˜ìˆ˜ì¦ ê²€ì¦ + Webhook í™˜ë¶ˆ ì²˜ë¦¬",
              "en": "```typescript\n// Google Play receipt verification API\nexport async function POST(request: Request) {\n  const { purchaseToken, productId } = await request.json();\n  \n  // 1. Verify receipt with Google Play API\n  const auth = new GoogleAuth({ credentials });\n  const client = await auth.getClient();\n  const response = await client.request({\n    url: `https://androidpublisher.googleapis.com/...`,\n    method: 'GET'\n  });\n  \n  // 2. Check purchase state\n  if (response.data.purchaseState !== 0) {\n    throw new Error('Invalid purchase');\n  }\n  \n  // 3. Record payment & grant premium\n  await prisma.user.update({\n    where: { id: userId },\n    data: { tier: 'PREMIUM', premiumExpiresAt }\n  });\n}\n```\n\n**Key**: Platform-specific receipt verification + Webhook refund handling"
            },
            "csFoundations": [
              "Payment Gateway Integration",
              "Receipt Verification",
              "Webhook Processing",
              "Cross-platform Development"
            ],
            "impact": {
              "ko": "**ì„±ê³¼**: Web/iOS/Android **3ê°œ í”Œë«í¼ ê²°ì œ í†µí•©**. í™˜ë¶ˆ ì‹œ ê¶Œí•œ ìë™ ì·¨ì†Œ. ê²°ì œ ì„±ê³µë¥  **99%+**.",
              "en": "**Impact**: **Unified payment across 3 platforms** (Web/iOS/Android). Auto-revoke on refund. Payment success rate **99%+**."
            },
            "commits": ["66d81f6", "e9a79a4", "632c2b4"]
          }
        ],
        "architecture": [
          {
            "title": {
              "ko": "AI í”¼ë“œë°± íŒŒì´í”„ë¼ì¸",
              "en": "AI Feedback Pipeline"
            },
            "description": {
              "ko": "ìŒì„± ë…¹ìŒë¶€í„° Gemini AI ë¶„ì„, êµ¬ì¡°í™”ëœ í”¼ë“œë°± ë Œë”ë§ê¹Œì§€ì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸. STT â†’ 5ê°œ ì˜ì—­ ë¶„ì„ â†’ ì¸ë¼ì¸ ë¬¸ë²• êµì • â†’ ëª¨ë²” ë‹µì•ˆ ìƒì„± íë¦„.",
              "en": "Complete pipeline from audio recording through Gemini AI analysis to structured feedback rendering. STT â†’ 5-domain analysis â†’ inline grammar correction â†’ model answer generation flow."
            },
            "mermaidFilePath": {
              "ko": "/architecture/opic-master/feedback-pipeline.mmd",
              "en": "/architecture/opic-master/feedback-pipeline-en.mmd"
            }
          },
          {
            "title": {
              "ko": "í¬ë¡œìŠ¤í”Œë«í¼ ì•„í‚¤í…ì²˜",
              "en": "Cross-platform Architecture"
            },
            "description": {
              "ko": "Next.js ì›¹ì•±ì„ Capacitorë¡œ ë˜í•‘í•˜ì—¬ iOS/Android ë„¤ì´í‹°ë¸Œ ì•± ìƒì„±. ë„¤ì´í‹°ë¸Œ í”ŒëŸ¬ê·¸ì¸ í†µí•© ë° í”Œë«í¼ë³„ ë¶„ê¸° ì²˜ë¦¬.",
              "en": "Wrapping Next.js web app with Capacitor to create iOS/Android native apps. Native plugin integration and platform-specific branching."
            },
            "mermaidFilePath": {
              "ko": "/architecture/opic-master/cross-platform.mmd",
              "en": "/architecture/opic-master/cross-platform-en.mmd"
            }
          }
        ]
      },
      "featured": true,
      "order": 2
    },
    {
      "id": "evaluator",
      "title": "Evaluator",
      "shortDescription": {
        "ko": "RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€ ìë™í™” í”Œë«í¼",
        "en": "Automated RAG System Performance Evaluation Platform"
      },
      "fullDescription": {
        "ko": "LLM ê¸°ë°˜ RAG ì‹œìŠ¤í…œì˜ ì •í™•ë„ë¥¼ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ìë™í™” í”Œë«í¼ì…ë‹ˆë‹¤. Recall/VecDash ë©”íŠ¸ë¦­ì„ í™œìš©í•˜ì—¬ QnA ìƒì„±ë¶€í„° ê²€ìƒ‰ ì •í™•ë„, ìƒì„± í’ˆì§ˆê¹Œì§€ E2E í‰ê°€ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤.",
        "en": "Comprehensive automated platform for evaluating LLM-based RAG system accuracy. Built an end-to-end evaluation pipeline from QnA generation to retrieval accuracy and generation quality using Recall/VecDash metrics."
      },
      "techStack": ["Python", "FastAPI", "OpenAI GPT-4o", "MinIO", "SSE", "Docker"],
      "keyAchievements": [
        {
          "ko": "LLM ê¸°ë°˜ í‰ê°€ ì—ì´ì „íŠ¸ (Intent Router + Request Builder)",
          "en": "LLM-based evaluation agent (Intent Router + Request Builder)"
        },
        {
          "ko": "Recall/VecDash ë©”íŠ¸ë¦­ ê¸°ë°˜ E2E í‰ê°€ ì‹œìŠ¤í…œ (QnA ìƒì„± â†’ ê²€ìƒ‰ ê²€ì¦ â†’ í’ˆì§ˆ í‰ê°€)",
          "en": "E2E evaluation system based on Recall/VecDash metrics (QnA generation â†’ retrieval validation â†’ quality assessment)"
        },
        {
          "ko": "Multi-LLM í‰ê°€ íŒŒì´í”„ë¼ì¸ ì„¤ê³„ (ìì—°ì–´ ì˜ë„ ê¸°ë°˜ ë¼ìš°íŒ…)",
          "en": "Designed multi-LLM evaluation pipeline (natural language intent-based routing)"
        },
        {
          "ko": "ì‹¤ì‹œê°„ ì§„í–‰ë¥  ì¶”ì  ë° ì—ëŸ¬ ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬í˜„",
          "en": "Implemented real-time progress tracking and error notification system"
        },
        {
          "ko": "í‰ê°€ ê²°ê³¼ Markdown ì‹œê°í™” ë° ë¦¬í¬íŒ… ìë™í™”",
          "en": "Automated evaluation result visualization and reporting in Markdown"
        }
      ],
      "features": [
        "Agentic RAG Evaluator",
        "Custom Recall & VecDash Metrics",
        "Automated QnA Generation",
        "Real-time Progress Tracking",
        "Markdown Result Visualization"
      ],
      "repoPath": "evaluator",
      "company": {
        "ko": "(ì£¼)í¬ì§€íë¸Œ",
        "en": "Posicube Inc."
      },
      "period": {
        "ko": "2025.02 ~ í˜„ì¬",
        "en": "Feb 2025 ~ Present"
      },
      "detail": {
        "problemSolving": [
          {
            "id": "progress-tracker",
            "title": {
              "ko": "Progress Tracker ì„¤ê³„",
              "en": "Progress Tracker Design"
            },
            "category": {
              "ko": "ë™ì‹œì„±",
              "en": "Concurrency"
            },
            "icon": "ğŸ“Š",
            "problem": {
              "ko": "ëŒ€ê·œëª¨ í‰ê°€ ì‘ì—…(ìˆ˜ë°±~ìˆ˜ì²œ ê°œ QnA) ì‹¤í–‰ ì‹œ ì‚¬ìš©ìëŠ” ì§„í–‰ ìƒí™©ì„ ì•Œ ìˆ˜ ì—†ê³ , ë§¤ ì‘ì—…ë§ˆë‹¤ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹œ API ì„œë²„ ë¶€í•˜ ê³¼ë‹¤ ë°œìƒ. ë˜í•œ ì´ì „ ë‹¨ê³„ í‰ê°€ ê²°ê³¼ê°€ ìœ ì‹¤ë˜ëŠ” ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤.",
              "en": "During large-scale evaluation tasks (hundreds to thousands of QnAs), users had no visibility into progress, and updating status for every task caused excessive API server load. Additionally, previous stage evaluation results were being lost."
            },
            "solution": {
              "ko": "**ProgressTracker í´ë˜ìŠ¤**ë¥¼ ì„¤ê³„í•˜ì—¬ 10% ë‹¨ìœ„ë¡œë§Œ ì§„í–‰ë¥ ì„ DataHub APIì— ë³´ê³ í•˜ë„ë¡ ìµœì í™”í–ˆìŠµë‹ˆë‹¤. **Prefix message íŒ¨í„´**ì„ ë„ì…í•˜ì—¬ ì´ì „ ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ í˜„ì¬ ì—…ë°ì´íŠ¸ ë©”ì‹œì§€ ì•ì— prependí•¨ìœ¼ë¡œì¨ í‰ê°€ íˆìŠ¤í† ë¦¬ë¥¼ ë³´ì¡´í–ˆìŠµë‹ˆë‹¤.",
              "en": "Designed a **ProgressTracker class** to optimize progress reporting to DataHub API at 10% intervals only. Introduced a **prefix message pattern** that prepends previous stage results to current update messages."
            },
            "technicalDetails": {
              "ko": "```python\nclass ProgressTracker:\n    def __init__(self, total, interval=10):\n        self.total = total\n        self.interval = interval\n        self.current = 0\n        self.last_percent = 0\n    \n    async def update(self, inc=1):\n        self.current += inc\n        percent = int((self.current / self.total) * 100)\n        \n        # Decile-based: 10% ë‹¨ìœ„ë¡œë§Œ API í˜¸ì¶œ\n        if percent // self.interval > self.last_percent // self.interval:\n            self.last_percent = percent\n            await self._send_update()  # 1000ê°œ â†’ 10ë²ˆë§Œ\n```\n\n**í•µì‹¬**: API í˜¸ì¶œ 1000ë²ˆ â†’ 10ë²ˆ (99% ê°ì†Œ)",
              "en": "```python\nclass ProgressTracker:\n    def __init__(self, total, interval=10):\n        self.total = total\n        self.interval = interval\n        self.current = 0\n        self.last_percent = 0\n    \n    async def update(self, inc=1):\n        self.current += inc\n        percent = int((self.current / self.total) * 100)\n        \n        # Decile-based: API calls only at 10% intervals\n        if percent // self.interval > self.last_percent // self.interval:\n            self.last_percent = percent\n            await self._send_update()  # 1000 tasks â†’ 10 calls\n```\n\n**Key**: API calls 1000 â†’ 10 (99% reduction)"
            },
            "csFoundations": [
              "Rate Limiting",
              "State Accumulation",
              "Progress Tracking",
              "API Optimization"
            ],
            "impact": {
              "ko": "API ì„œë²„ ë¶€í•˜ **99% ê°ì†Œ**, í‰ê°€ ê²°ê³¼ ì†ì‹¤ **ì œë¡œí™”**, ì‚¬ìš©ì ê²½í—˜ ê°œì„ ",
              "en": "API server load reduced by **99%**, evaluation result loss **eliminated**, improved UX"
            }
          },
          {
            "id": "multi-processor-pattern",
            "title": {
              "ko": "Multi-Processor Pattern ë„ì…",
              "en": "Multi-Processor Pattern"
            },
            "category": {
              "ko": "ì„¤ê³„íŒ¨í„´",
              "en": "Design Pattern"
            },
            "icon": "ğŸ­",
            "problem": {
              "ko": "Recall, Ragas, VecDash, Pipeline ë“± 4ê°€ì§€ í‰ê°€ íƒ€ì…ë§ˆë‹¤ ì¤‘ë³µëœ íŒŒì¼ ë¡œë”©, ì—ëŸ¬ ì²˜ë¦¬, ë¡œê¹… ë¡œì§ì´ ë°˜ë³µ êµ¬í˜„ë˜ì–´ ìˆì—ˆê³ , ì‹ ê·œ í‰ê°€ ë°©ì‹ ì¶”ê°€ ì‹œ ë³´ì¼ëŸ¬í”Œë ˆì´íŠ¸ ì½”ë“œê°€ ì¦ê°€í–ˆìŠµë‹ˆë‹¤.",
              "en": "For four evaluation types (Recall, Ragas, VecDash, Pipeline), duplicate file loading, error handling, and logging logic was repeatedly implemented."
            },
            "solution": {
              "ko": "**Template Method íŒ¨í„´** ê¸°ë°˜ `BaseEvaluationProcessor` ì¶”ìƒ í´ë˜ìŠ¤ë¥¼ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤. ê³µí†µ íë¦„(`run()`)ì€ ë¶€ëª¨ì—ì„œ ì •ì˜í•˜ê³ , í‰ê°€ë³„ í•µì‹¬ ë¡œì§ë§Œ ì„œë¸Œí´ë˜ìŠ¤ê°€ êµ¬í˜„í•˜ë„ë¡ ê°•ì œí–ˆìŠµë‹ˆë‹¤.",
              "en": "Designed `BaseEvaluationProcessor` abstract class based on **Template Method pattern**. Common flow (`run()`) defined in parent class, evaluation-specific logic in subclasses."
            },
            "technicalDetails": {
              "ko": "```python\nfrom abc import ABC, abstractmethod\n\nclass BaseEvaluationProcessor(ABC):\n    async def run(self):\n        try:\n            data = await self._load_input()  # ì¶”ìƒ\n            result = await self._process(data)\n            return await self._save_output(result)\n        except Exception as e:\n            logger.error(f\"Failed: {e}\")\n            raise\n    \n    @abstractmethod\n    async def _load_input(self): pass\n    \n    @abstractmethod\n    async def _process(self, data): pass\n```\n\n**í•µì‹¬**: Template Method + Factoryë¡œ ì½”ë“œ ì¤‘ë³µ 70% ê°ì†Œ",
              "en": "```python\nfrom abc import ABC, abstractmethod\n\nclass BaseEvaluationProcessor(ABC):\n    async def run(self):\n        try:\n            data = await self._load_input()  # abstract\n            result = await self._process(data)\n            return await self._save_output(result)\n        except Exception as e:\n            logger.error(f\"Failed: {e}\")\n            raise\n    \n    @abstractmethod\n    async def _load_input(self): pass\n    \n    @abstractmethod\n    async def _process(self, data): pass\n```\n\n**Key**: Template Method + Factory reduced duplication by 70%"
            },
            "csFoundations": [
              "Template Method Pattern",
              "Factory Pattern",
              "Dependency Injection",
              "Abstract Base Class"
            ],
            "impact": {
              "ko": "ì½”ë“œ ì¤‘ë³µ **70% ê°ì†Œ**, ì‹ ê·œ í‰ê°€ íƒ€ì… ì¶”ê°€ ì‹œê°„ **3ì¼ â†’ 4ì‹œê°„**, í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ **45% â†’ 85%**",
              "en": "Code duplication reduced by **70%**, new evaluation type time **3 days â†’ 4 hours**, test coverage **45% â†’ 85%**"
            }
          },
          {
            "id": "async-job-processing",
            "title": {
              "ko": "ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬ ì‹œìŠ¤í…œ",
              "en": "Async Job Processing"
            },
            "category": {
              "ko": "ì„±ëŠ¥ìµœì í™”",
              "en": "Performance"
            },
            "icon": "â±ï¸",
            "problem": {
              "ko": "ìˆ˜ë°± ê°œì˜ QnA í‰ê°€ ì‘ì—…ì„ ë™ê¸°ì‹ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©´ API íƒ€ì„ì•„ì›ƒì´ ë°œìƒí•˜ê³ , ì‚¬ìš©ìëŠ” ì‘ì—… ì™„ë£Œê¹Œì§€ ë¸Œë¼ìš°ì €ë¥¼ ë‹«ì„ ìˆ˜ ì—†ì–´ UXê°€ ì €í•˜ë˜ì—ˆìŠµë‹ˆë‹¤.",
              "en": "Processing hundreds of QnA evaluation tasks synchronously caused API timeouts, and users couldn't close their browsers until completion."
            },
            "solution": {
              "ko": "`chat_logs_id` íŒŒë¼ë¯¸í„° ê¸°ë°˜ ë™ê¸°/ë¹„ë™ê¸° ì‹¤í–‰ ë¶„ê¸°. `asyncio.create_task()`ë¡œ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ìƒì„±í•˜ê³  ì¦‰ì‹œ ì‘ë‹µ ë°˜í™˜. ì‘ì—… ìƒíƒœë¥¼ ProgressTrackerë¥¼ í†µí•´ ì‹¤ì‹œê°„ ë³´ê³ .",
              "en": "Implemented sync/async branching based on `chat_logs_id` parameter. Creates background task with `asyncio.create_task()` and returns immediately."
            },
            "technicalDetails": {
              "ko": "```python\n@router.post(\"/evaluation/ragas\")\nasync def submit_evaluation(request, chat_logs_id: Optional[int]):\n    processor = get_processor(\"ragas\", request)\n    \n    if chat_logs_id:\n        # ë¹„ë™ê¸°: ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰\n        asyncio.create_task(run_job(processor, chat_logs_id))\n        return {\"status\": \"queued\"}\n    else:\n        # ë™ê¸°: ì¦‰ì‹œ ì™„ë£Œ\n        await processor.run()\n        return {\"status\": \"completed\"}\n```\n\n**í•µì‹¬**: Event Loopì—ì„œ ë…ë¦½ ì‹¤í–‰, ì¦‰ì‹œ ì‘ë‹µ",
              "en": "```python\n@router.post(\"/evaluation/ragas\")\nasync def submit_evaluation(request, chat_logs_id: Optional[int]):\n    processor = get_processor(\"ragas\", request)\n    \n    if chat_logs_id:\n        # Async: background execution\n        asyncio.create_task(run_job(processor, chat_logs_id))\n        return {\"status\": \"queued\"}\n    else:\n        # Sync: immediate completion\n        await processor.run()\n        return {\"status\": \"completed\"}\n```\n\n**Key**: Independent execution in Event Loop"
            },
            "csFoundations": [
              "Async Programming",
              "Event Loop",
              "Graceful Error Handling",
              "Background Tasks"
            ],
            "impact": {
              "ko": "API íƒ€ì„ì•„ì›ƒ **ì œë¡œí™”**, ì‚¬ìš©ì ëŒ€ê¸° ì‹œê°„ **95% ê°ì†Œ**, ìš´ì˜ íš¨ìœ¨ì„± **150% í–¥ìƒ**",
              "en": "API timeouts **eliminated**, user wait time reduced by **95%**, operational efficiency improved by **150%**"
            }
          }
        ],
        "architecture": [
          {
            "title": {
              "ko": "ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜",
              "en": "System Architecture"
            },
            "description": {
              "ko": "Evaluatorì˜ ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì¡°. API Layer, Processor Factory, Base Processor Pattern, Evaluation Layer, Progress Tracking, External Services ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.",
              "en": "Overall system structure of Evaluator. Shows interactions between API Layer, Processor Factory, Base Processor Pattern, Evaluation Layer, Progress Tracking, and External Services."
            },
            "mermaidFilePath": {
              "ko": "/architecture/evaluator/system-architecture.mmd",
              "en": "/architecture/evaluator/system-architecture-en.mmd"
            }
          },
          {
            "title": {
              "ko": "í‰ê°€ íŒŒì´í”„ë¼ì¸ í”Œë¡œìš°",
              "en": "Evaluation Pipeline Flow"
            },
            "description": {
              "ko": "QnA ìƒì„± â†’ Recall í‰ê°€ â†’ Ragas í‰ê°€ë¡œ ì´ì–´ì§€ëŠ” E2E í‰ê°€ íŒŒì´í”„ë¼ì¸ì˜ ìƒì„¸ íë¦„. ê° ë‹¨ê³„ë³„ Progress Tracking, íŒŒì¼ ê´€ë¦¬, ë¹„ë™ê¸° ì²˜ë¦¬ ë©”ì»¤ë‹ˆì¦˜ì„ í¬í•¨í•©ë‹ˆë‹¤.",
              "en": "Detailed flow of the E2E evaluation pipeline from QnA Generation â†’ Recall Evaluation â†’ Ragas Evaluation. Includes Progress Tracking, file management, and async processing mechanisms for each stage."
            },
            "mermaidFilePath": {
              "ko": "/architecture/evaluator/evaluation-pipeline.mmd",
              "en": "/architecture/evaluator/evaluation-pipeline-en.mmd"
            }
          }
        ]
      },
      "featured": false,
      "order": 1
    },
    {
      "id": "py-editor",
      "title": "PyEditor",
      "shortDescription": {
        "ko": "ë¸Œë¼ìš°ì € ê¸°ë°˜ Python í†µí•© ê°œë°œ í™˜ê²½",
        "en": "Browser-based Python Integrated Development Environment"
      },
      "fullDescription": {
        "ko": "Monaco Editorì™€ Python LSPë¥¼ ì—°ë™í•œ VSCode ìŠ¤íƒ€ì¼ ì›¹ IDEì…ë‹ˆë‹¤. Custom Process Poolì„ í†µí•´ ë©€í‹°ìœ ì € í™˜ê²½ì—ì„œë„ ì•ˆì •ì ì¸ LSP ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ë©°, WebSocket ê¸°ë°˜ ì €ì§€ì—° í†µì‹ ìœ¼ë¡œ ì‹¤ì‹œê°„ ìë™ì™„ì„±ê³¼ Go-to-Definitionì„ ì§€ì›í•©ë‹ˆë‹¤.",
        "en": "VSCode-style web IDE integrating Monaco Editor with Python LSP. Provides stable LSP service in multi-user environments through custom process pooling, and supports real-time auto-completion and go-to-definition via low-latency WebSocket communication."
      },
      "techStack": [
        "Vanilla JS (Vite)",
        "Monaco Editor",
        "Node.js",
        "Express",
        "WebSocket",
        "Python LSP",
        "Docker"
      ],
      "keyAchievements": [
        {
          "ko": "Custom Process Poolë¡œ pylsp íš¨ìœ¨ì  ê´€ë¦¬ (ë©€í‹°ìœ ì € ë©”ëª¨ë¦¬ ìµœì í™”)",
          "en": "Efficient pylsp management with custom process pool (multi-user memory optimization)"
        },
        {
          "ko": "WebSocket ì–‘ë°©í–¥ JSON-RPC í”„ë¡ì‹œ (Monaco â†” Python LSP)",
          "en": "Bi-directional WebSocket JSON-RPC proxy (Monaco â†” Python LSP)"
        },
        {
          "ko": "1MB ë©”ì‹œì§€ ë²„í¼ë§ & Stale Request ìë™ ì •ë¦¬ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)",
          "en": "1MB message buffering & automatic stale request cleanup (memory leak prevention)"
        },
        {
          "ko": "Context-Aware AI Copilot (ì½”ë“œ ë¶„ì„ + RAG íŒŒì´í”„ë¼ì¸)",
          "en": "Context-aware AI Copilot (code analysis + RAG pipeline)"
        },
        {
          "ko": "ìœ íœ´ í”„ë¡œì„¸ìŠ¤ ìë™ íšŒìˆ˜ & ì¢€ë¹„ í”„ë¡œì„¸ìŠ¤ ë°©ì§€ ë¡œì§",
          "en": "Automatic idle process cleanup & zombie process prevention logic"
        }
      ],
      "features": [
        "Real-time LSP Integration",
        "Multi-user Process Pooling",
        "WebSocket JSON-RPC Proxy",
        "Context-aware AI Copilot",
        "Git Integration & Diff Viewer"
      ],
      "repoPath": "py-editor",
      "company": {
        "ko": "(ì£¼)í¬ì§€íë¸Œ",
        "en": "Posicube Inc."
      },
      "period": {
        "ko": "2025.06 ~ í˜„ì¬",
        "en": "Jun 2025 ~ Present"
      },
      "detail": {
        "problemSolving": [
          {
            "id": "lsp-process-pool",
            "title": {
              "ko": "LSP Process Pool ì„¤ê³„",
              "en": "LSP Process Pool Design"
            },
            "category": {
              "ko": "ì„±ëŠ¥ìµœì í™”",
              "en": "Performance"
            },
            "icon": "ğŸŠ",
            "problem": {
              "ko": "ë©€í‹°ìœ ì € í™˜ê²½ì—ì„œ ê° ì‚¬ìš©ìë§ˆë‹¤ Python LSP í”„ë¡œì„¸ìŠ¤ë¥¼ ìƒì„±í•˜ë©´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ í­ë°œì ìœ¼ë¡œ ì¦ê°€í•©ë‹ˆë‹¤. 20ëª…ì´ ë™ì‹œ ì ‘ì†í•˜ë©´ 20ê°œ pylsp í”„ë¡œì„¸ìŠ¤ Ã— 150MB = 3GB ë©”ëª¨ë¦¬ ì†Œë¹„.",
              "en": "Creating a Python LSP process for each user in a multi-user environment causes explosive memory growth. 20 concurrent users = 20 pylsp processes Ã— 150MB = 3GB memory consumption."
            },
            "solution": {
              "ko": "**Object Pool Pattern** ê¸°ë°˜ LSP Process Poolì„ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤. ìµœëŒ€ 20ê°œ í”„ë¡œì„¸ìŠ¤ë¡œ ì œí•œí•˜ê³ , Idle Timeout(5ë¶„)ìœ¼ë¡œ ìë™ ì •ë¦¬í•©ë‹ˆë‹¤. ì‚¬ìš©ì ì—°ê²° í•´ì œ ì‹œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•˜ì§€ ì•Šê³  Poolì— ë°˜í™˜í•˜ì—¬ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.",
              "en": "Designed LSP Process Pool based on **Object Pool Pattern**. Limited to max 20 processes with idle timeout (5 min) for automatic cleanup. Processes are returned to pool instead of being killed when users disconnect."
            },
            "technicalDetails": {
              "ko": "```\nclass LSPProcessPool {\n  constructor(maxProcesses = 20, idleTimeout = 300000) {\n    this.maxProcesses = maxProcesses;\n    this.idleTimeout = idleTimeout;\n    this.processes = new Map(); // userId -> process\n    this.idleProcesses = [];\n  }\n\n  async getOrCreateProcess(userId) {\n    // 1. ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì¬ì‚¬ìš©\n    if (this.processes.has(userId)) {\n      return this.processes.get(userId);\n    }\n    \n    // 2. Idle í”„ë¡œì„¸ìŠ¤ ì¬í™œìš©\n    if (this.idleProcesses.length > 0) {\n      const process = this.idleProcesses.pop();\n      this.processes.set(userId, process);\n      return process;\n    }\n    \n    // 3. ìƒˆ í”„ë¡œì„¸ìŠ¤ ìƒì„± (ìµœëŒ€ 20ê°œ)\n    if (this.processes.size < this.maxProcesses) {\n      const process = await this.createProcess();\n      this.processes.set(userId, process);\n      return process;\n    }\n    \n    throw new Error('Process pool exhausted');\n  }\n  \n  releaseProcess(userId) {\n    const process = this.processes.get(userId);\n    this.processes.delete(userId);\n    this.idleProcesses.push(process);\n    \n    // 5ë¶„ í›„ ìë™ ì¢…ë£Œ\n    setTimeout(() => this.killIdleProcess(process), this.idleTimeout);\n  }\n}\n```\n\n**í•µì‹¬**: í”„ë¡œì„¸ìŠ¤ ì¬ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ 70% ê°ì†Œ",
              "en": "```\nclass LSPProcessPool {\n  constructor(maxProcesses = 20, idleTimeout = 300000) {\n    this.maxProcesses = maxProcesses;\n    this.idleTimeout = idleTimeout;\n    this.processes = new Map(); // userId -> process\n    this.idleProcesses = [];\n  }\n\n  async getOrCreateProcess(userId) {\n    // 1. Reuse existing process\n    if (this.processes.has(userId)) {\n      return this.processes.get(userId);\n    }\n    \n    // 2. Recycle idle process\n    if (this.idleProcesses.length > 0) {\n      const process = this.idleProcesses.pop();\n      this.processes.set(userId, process);\n      return process;\n    }\n    \n    // 3. Create new process (max 20)\n    if (this.processes.size < this.maxProcesses) {\n      const process = await this.createProcess();\n      this.processes.set(userId, process);\n      return process;\n    }\n    \n    throw new Error('Process pool exhausted');\n  }\n  \n  releaseProcess(userId) {\n    const process = this.processes.get(userId);\n    this.processes.delete(userId);\n    this.idleProcesses.push(process);\n    \n    // Auto-kill after 5 min\n    setTimeout(() => this.killIdleProcess(process), this.idleTimeout);\n  }\n}\n```\n\n**Key**: Process reuse reduced memory by 70%"
            },
            "csFoundations": [
              "Object Pool Pattern",
              "Resource Management",
              "Lazy Initialization",
              "Cache Eviction"
            ],
            "impact": {
              "ko": "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ **70% ê°ì†Œ**, 20ëª… ë™ì‹œ ì‚¬ìš©ì ì§€ì›, LSP ì‘ë‹µ ì‹œê°„ **40% ë‹¨ì¶•**",
              "en": "Memory usage reduced by **70%**, supports 20 concurrent users, LSP response time improved by **40%**"
            }
          },
          {
            "id": "concurrency-limiter",
            "title": {
              "ko": "LLM API Concurrency Limiter",
              "en": "LLM API Concurrency Limiter"
            },
            "category": {
              "ko": "ë™ì‹œì„±",
              "en": "Concurrency"
            },
            "icon": "ğŸš¦",
            "problem": {
              "ko": "100ê°œì˜ ë™ì‹œ AI Copilot ìš”ì²­ì´ ë°œìƒí•˜ë©´ ê° ìš”ì²­ë§ˆë‹¤ context building(ë©”ëª¨ë¦¬ ì§‘ì•½ì )ì´ ì‹¤í–‰ë˜ì–´ ì„œë²„ ë©”ëª¨ë¦¬ ìŠ¤íŒŒì´í¬ ë°œìƒ. ë°±ì—”ë“œ LBë¡œë„ í•´ê²° ë¶ˆê°€.",
              "en": "100 concurrent AI Copilot requests trigger context building (memory intensive) for each request, causing server memory spikes. Backend LB cannot prevent this."
            },
            "solution": {
              "ko": "`p-limit` ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸°ë°˜ Concurrency Limiterë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. ìµœëŒ€ 10ê°œ ë™ì‹œ ìš”ì²­ìœ¼ë¡œ ì œí•œí•˜ê³ , ì´ˆê³¼ ìš”ì²­ì€ ìë™ìœ¼ë¡œ ëŒ€ê¸°ì—´ì— ì ì¬ë©ë‹ˆë‹¤. Statistics trackingìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.",
              "en": "Implemented Concurrency Limiter based on `p-limit` library. Limited to max 10 concurrent requests with automatic queueing for excess requests. Includes statistics tracking for monitoring."
            },
            "technicalDetails": {
              "ko": "```\nconst pLimit = require('p-limit');\n\nclass ConcurrencyLimiter {\n  constructor(maxConcurrent = 10) {\n    this.limit = pLimit(maxConcurrent);\n    this.stats = {\n      currentActive: 0,\n      currentQueued: 0,\n      peakActive: 0,\n      peakQueued: 0\n    };\n  }\n  \n  async execute(fn) {\n    this.stats.currentQueued++;\n    \n    return this.limit(async () => {\n      this.stats.currentQueued--;\n      this.stats.currentActive++;\n      \n      try {\n        const result = await fn();\n        return result;\n      } finally {\n        this.stats.currentActive--;\n      }\n    });\n  }\n  \n  getStats() {\n    return this.stats;\n  }\n}\n\n// Usage\nconst limiter = new ConcurrencyLimiter(10);\nawait limiter.execute(() => callLLMAPI());\n```\n\n**í•µì‹¬**: Semaphore íŒ¨í„´ìœ¼ë¡œ ë™ì‹œ ì‹¤í–‰ ì œí•œ",
              "en": "```\nconst pLimit = require('p-limit');\n\nclass ConcurrencyLimiter {\n  constructor(maxConcurrent = 10) {\n    this.limit = pLimit(maxConcurrent);\n    this.stats = {\n      currentActive: 0,\n      currentQueued: 0,\n      peakActive: 0,\n      peakQueued: 0\n    };\n  }\n  \n  async execute(fn) {\n    this.stats.currentQueued++;\n    \n    return this.limit(async () => {\n      this.stats.currentQueued--;\n      this.stats.currentActive++;\n      \n      try {\n        const result = await fn();\n        return result;\n      } finally {\n        this.stats.currentActive--;\n      }\n    });\n  }\n  \n  getStats() {\n    return this.stats;\n  }\n}\n\n// Usage\nconst limiter = new ConcurrencyLimiter(10);\nawait limiter.execute(() => callLLMAPI());\n```\n\n**Key**: Semaphore pattern limits concurrent execution"
            },
            "csFoundations": ["Rate Limiting", "Semaphore", "Queue Management", "Backpressure"],
            "impact": {
              "ko": "ë©”ëª¨ë¦¬ ìŠ¤íŒŒì´í¬ **ì œë¡œí™”**, API íƒ€ì„ì•„ì›ƒ **99% ê°ì†Œ**, ì„œë²„ ì•ˆì •ì„± í™•ë³´",
              "en": "Memory spikes **eliminated**, API timeouts reduced by **99%**, server stability ensured"
            }
          },
          {
            "id": "path-access-control",
            "title": {
              "ko": "Path-based Access Control",
              "en": "Path-based Access Control"
            },
            "category": {
              "ko": "ë³´ì•ˆ",
              "en": "Security"
            },
            "icon": "ğŸ›¡ï¸",
            "problem": {
              "ko": "ë¸Œë¼ìš°ì € í´ë¼ì´ì–¸íŠ¸ê°€ ì‹œìŠ¤í…œ ê²½ë¡œ(/constants, /llms)ì— ì ‘ê·¼í•˜ë©´ ë¯¼ê°í•œ ì„¤ì • íŒŒì¼ì´ ë…¸ì¶œë©ë‹ˆë‹¤. ì™¸ë¶€ FastAPI ì„œë¹„ìŠ¤ëŠ” ëª¨ë“  ê²½ë¡œ ì ‘ê·¼ì´ í•„ìš”í•˜ì§€ë§Œ, ë¸Œë¼ìš°ì €ëŠ” /workspaceë§Œ í—ˆìš©í•´ì•¼ í•©ë‹ˆë‹¤.",
              "en": "Browser clients accessing system paths (/constants, /llms) exposes sensitive configuration files. External FastAPI services need full path access, but browsers should only access /workspace."
            },
            "solution": {
              "ko": "**X-Service-Auth í—¤ë”** ê¸°ë°˜ ì¸ì¦ìœ¼ë¡œ í˜¸ì¶œìë¥¼ êµ¬ë¶„í•©ë‹ˆë‹¤. í† í°ì´ ìˆìœ¼ë©´ ì™¸ë¶€ ì„œë¹„ìŠ¤ë¡œ ì¸ì‹í•˜ì—¬ ì „ì²´ ê²½ë¡œ í—ˆìš©, ì—†ìœ¼ë©´ ë¸Œë¼ìš°ì € í´ë¼ì´ì–¸íŠ¸ë¡œ ê°„ì£¼í•˜ì—¬ /workspaceë§Œ í—ˆìš©í•©ë‹ˆë‹¤.",
              "en": "Implemented caller distinction based on **X-Service-Auth header**. With token = external service (full access), without token = browser client (workspace only)."
            },
            "technicalDetails": {
              "ko": "```\nfunction pathAccessControl(req, res, next) {\n  const authHeader = req.headers['x-service-auth'];\n  const isService = authHeader === process.env.SERVICE_AUTH_TOKEN;\n  \n  // External service: full access\n  if (isService) {\n    return next();\n  }\n  \n  // Browser client: check restricted paths\n  const folder = req.query.folder || '';\n  const RESTRICTED = ['/constants', '/llms'];\n  \n  for (const restricted of RESTRICTED) {\n    const normalized = restricted.replace(/^\\/+/, '');\n    const folderPath = folder.replace(/^\\/+/, '');\n    \n    if (folderPath === normalized || \n        folderPath.startsWith(normalized + '/')) {\n      return res.status(403).json({\n        error: 'Access denied',\n        message: 'Browser clients cannot access system paths'\n      });\n    }\n  }\n  \n  next();\n}\n\napp.use('/api/files', pathAccessControl);\n```\n\n**í•µì‹¬**: Middlewareë¡œ ê²½ë¡œ ê¸°ë°˜ ê²©ë¦¬ êµ¬í˜„",
              "en": "```\nfunction pathAccessControl(req, res, next) {\n  const authHeader = req.headers['x-service-auth'];\n  const isService = authHeader === process.env.SERVICE_AUTH_TOKEN;\n  \n  // External service: full access\n  if (isService) {\n    return next();\n  }\n  \n  // Browser client: check restricted paths\n  const folder = req.query.folder || '';\n  const RESTRICTED = ['/constants', '/llms'];\n  \n  for (const restricted of RESTRICTED) {\n    const normalized = restricted.replace(/^\\/+/, '');\n    const folderPath = folder.replace(/^\\/+/, '');\n    \n    if (folderPath === normalized || \n        folderPath.startsWith(normalized + '/')) {\n      return res.status(403).json({\n        error: 'Access denied',\n        message: 'Browser clients cannot access system paths'\n      });\n    }\n  }\n  \n  next();\n}\n\napp.use('/api/files', pathAccessControl);\n```\n\n**Key**: Path-based isolation via middleware"
            },
            "csFoundations": [
              "Authorization",
              "Middleware Pattern",
              "Principle of Least Privilege",
              "Multi-tenancy"
            ],
            "impact": {
              "ko": "ë³´ì•ˆ ì·¨ì•½ì  **ì œë¡œí™”**, ë©€í‹°í…Œë„Œì‹œ ê²©ë¦¬ ì™„ë²½í™”, ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ë™ ìœ ì—°ì„± í™•ë³´",
              "en": "Security vulnerabilities **eliminated**, perfect multi-tenancy isolation, flexible external service integration"
            }
          }
        ],
        "architecture": [
          {
            "title": {
              "ko": "ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜",
              "en": "System Architecture"
            },
            "description": {
              "ko": "PyEditorì˜ ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì¡°. Client Layer, WebSocket Layer, Middleware, Service Layer, API Layer, External Resources ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.",
              "en": "Overall system structure of PyEditor. Shows interactions between Client Layer, WebSocket Layer, Middleware, Service Layer, API Layer, and External Resources."
            },
            "mermaidFilePath": {
              "ko": "/architecture/pyeditor/system-architecture.mmd",
              "en": "/architecture/pyeditor/system-architecture-en.mmd"
            }
          },
          {
            "title": {
              "ko": "LSP WebSocket í†µì‹  í”Œë¡œìš°",
              "en": "LSP WebSocket Communication Flow"
            },
            "description": {
              "ko": "WebSocket ì—°ê²°ë¶€í„° LSP ìš”ì²­/ì‘ë‹µ, íŒŒì¼ ë³€ê²½ ê°ì§€, Git ë™ê¸°í™”, ì—°ê²° ì¢…ë£Œê¹Œì§€ì˜ ì „ì²´ íë¦„. Process Poolì—ì„œì˜ í”„ë¡œì„¸ìŠ¤ í• ë‹¹/ë°˜í™˜ ë° Cache ê´€ë¦¬ ë©”ì»¤ë‹ˆì¦˜ì„ í¬í•¨í•©ë‹ˆë‹¤.",
              "en": "Complete flow from WebSocket connection to LSP request/response, file change detection, Git synchronization, and connection cleanup. Includes process allocation/release from pool and cache management mechanisms."
            },
            "mermaidFilePath": {
              "ko": "/architecture/pyeditor/lsp-websocket-flow.mmd",
              "en": "/architecture/pyeditor/lsp-websocket-flow-en.mmd"
            }
          }
        ]
      },
      "featured": false,
      "order": 2
    },
    {
      "id": "knowledge-base",
      "title": {
        "ko": "ì‚¬ë‚´ ì§€ì‹ë² ì´ìŠ¤ RAG",
        "en": "Internal Knowledge Base RAG"
      },
      "shortDescription": {
        "ko": "Self-Corrective RAG êµ¬ì¡°ë¡œ ì‚¬ë‚´ ë¶„ì‚° ì§€ì‹ í†µí•© ë° ê³ í’ˆì§ˆ ë‹µë³€ ì œê³µ",
        "en": "Self-Corrective RAG system integrating distributed internal knowledge"
      },
      "fullDescription": {
        "ko": "PM, íƒ€ë¶€ì„œ, B2B ì´í•´ê´€ê³„ì, ì‹ ì…ì‚¬ì›ì˜ ì—…ë¬´ íš¨ìœ¨í™”ë¥¼ ìœ„í•œ Self-Corrective RAG ì‹œìŠ¤í…œì…ë‹ˆë‹¤. í’ˆì§ˆ í‰ê°€ ê¸°ë°˜ ë°˜ë³µ ê²€ìƒ‰ê³¼ ëˆ„ì  ì»¨í…ìŠ¤íŠ¸ë¡œ ì¼ë°˜ RAG ëŒ€ë¹„ ë†’ì€ ì •í™•ë„ë¥¼ ì‹¤í˜„í–ˆìŠµë‹ˆë‹¤.",
        "en": "Self-Corrective RAG system for PMs, cross-department teams, B2B stakeholders, and new employees. Achieved higher accuracy than standard RAG through quality-driven iterative search and accumulated context."
      },
      "period": {
        "ko": "2024.10 ~ í˜„ì¬",
        "en": "Oct 2024 ~ Present"
      },
      "company": {
        "ko": "(ì£¼)í¬ì§€íë¸Œ",
        "en": "Posicube Inc."
      },
      "techStack": ["Python", "LangChain", "OpenAI GPT-4o", "Faiss", "Streamlit", "FastAPI"],
      "features": [
        {
          "ko": "Self-Corrective RAG Loop",
          "en": "Self-Corrective RAG Loop"
        },
        {
          "ko": "Progressive Context Accumulation",
          "en": "Progressive Context Accumulation"
        },
        {
          "ko": "Intelligent Query Refinement",
          "en": "Intelligent Query Refinement"
        },
        {
          "ko": "Hallucination Detection",
          "en": "Hallucination Detection"
        },
        {
          "ko": "Source Attribution",
          "en": "Source Attribution"
        }
      ],
      "keyAchievements": [
        {
          "ko": "ë‹µë³€ ì •í™•ë„ **85% â†’ 95%** í–¥ìƒ (Self-Correction ë„ì…)",
          "en": "Improved answer accuracy **85% â†’ 95%** (Introduced Self-Correction)"
        },
        {
          "ko": "ê²€ìƒ‰ ì„±ê³µë¥  **70% â†’ 90%** ê°œì„  (Query Refinement ì ìš©)",
          "en": "Improved retrieval success rate **70% â†’ 90%** (Applied Query Refinement)"
        },
        {
          "ko": "ë³µì¡í•œ ì§ˆë¬¸ ë‹µë³€ ì™„ì„±ë„ **+40%** (Context Accumulation)",
          "en": "Completeness for complex queries **+40%** (Context Accumulation)"
        },
        {
          "ko": "ì‹ ì…ì‚¬ì› ì˜¨ë³´ë”© ì‹œê°„ **50% ë‹¨ì¶•**",
          "en": "Reduced new employee onboarding time by **50%**"
        }
      ],
      "repoPath": "knowledge-base",
      "detail": {
        "problemSolving": [
          {
            "id": "self-corrective-loop",
            "title": {
              "ko": "Self-Corrective RAG: í’ˆì§ˆ í‰ê°€ ê¸°ë°˜ ë°˜ë³µ ê²€ìƒ‰",
              "en": "Self-Corrective RAG: Quality-Driven Iterative Search"
            },
            "category": {
              "ko": "RAGìµœì í™”",
              "en": "RAG Optimization"
            },
            "icon": "ğŸ”„",
            "problem": {
              "ko": "**ì´ìŠˆ**: ì¼ë°˜ RAGëŠ” ì²« ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì •í™•í•˜ê±°ë‚˜ ë¶ˆì¶©ë¶„í•´ë„ ì¬ì‹œë„ ì—†ì´ ê·¸ëŒ€ë¡œ ë‹µë³€ ìƒì„±. ì‚¬ë‚´ ë³µì¡í•œ ê¸°ìˆ  ì§ˆë¬¸ì˜ ê²½ìš° ì²« ê²€ìƒ‰ë§Œìœ¼ë¡œëŠ” ì ì ˆí•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ í™•ë³´í•˜ì§€ ëª»í•´ ì˜¤ë‹µë¥  15% ë°œìƒ.",
              "en": "**Issue**: Standard RAG generates answers without retry even when initial search results are inaccurate or insufficient. For complex internal technical questions, single search cannot secure appropriate context, resulting in 15% error rate."
            },
            "solution": {
              "ko": "**í•´ê²°**: GPT-4o-mini ê¸°ë°˜ í‰ê°€ LLMì„ ë„ì…í•˜ì—¬ ìƒì„±ëœ ë‹µë³€ì˜ í’ˆì§ˆì„ 70ì  ê¸°ì¤€ìœ¼ë¡œ ìë™ í‰ê°€. ì„ê³„ê°’ ë¯¸ë‹¬ ì‹œ ìµœëŒ€ 3íšŒê¹Œì§€ ê²€ìƒ‰ì–´ë¥¼ ê°œì„ í•˜ì—¬ ì¬ê²€ìƒ‰í•˜ëŠ” Self-Corrective Loop êµ¬í˜„. ì¬ì‹œë„ë§ˆë‹¤ ì´ì „ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ëˆ„ì í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì ì§„ì ìœ¼ë¡œ í™•ì¥.",
              "en": "**Solution**: Introduced GPT-4o-mini based evaluation LLM to automatically assess answer quality with 70-point threshold. Implemented Self-Corrective Loop that refines search queries and retries up to 3 times when below threshold. Progressively expands context by accumulating previous search results with each retry."
            },
            "technicalDetails": {
              "ko": "```python\\n# í’ˆì§ˆ í‰ê°€ ë£¨í”„\\nQUALITY_THRESHOLD = 70\\nMAX_RETRY = 3\\ncurrent_retry = 0\\n\\nwhile current_retry < MAX_RETRY:\\n    # ë‹µë³€ ìƒì„±\\n    answer = generate_answer(passages, question)\\n    \\n    # í’ˆì§ˆ í‰ê°€ (GPT-4o-mini)\\n    eval_result = evaluate_quality(answer, question)\\n    \\n    if eval_result.score >= QUALITY_THRESHOLD:\\n        return answer  # ë§Œì¡±\\n    \\n    # ê²€ìƒ‰ì–´ ê°œì„ \\n    refined_query = refine_keywords(\\n        question,\\n        eval_result.suggestions,\\n        accumulated_passages\\n    )\\n    \\n    # ì¬ê²€ìƒ‰ (ëˆ„ì )\\n    new_passages = search(refined_query)\\n    accumulated_passages.extend(new_passages)\\n    current_retry += 1\\n```\\n\\n**í•µì‹¬**: Quality Assurance Loop + Progressive Retrieval",
              "en": "```python\\n# Quality evaluation loop\\nQUALITY_THRESHOLD = 70\\nMAX_RETRY = 3\\ncurrent_retry = 0\\n\\nwhile current_retry < MAX_RETRY:\\n    # Generate answer\\n    answer = generate_answer(passages, question)\\n    \\n    # Quality evaluation (GPT-4o-mini)\\n    eval_result = evaluate_quality(answer, question)\\n    \\n    if eval_result.score >= QUALITY_THRESHOLD:\\n        return answer  # Satisfactory\\n    \\n    # Refine query\\n    refined_query = refine_keywords(\\n        question,\\n        eval_result.suggestions,\\n        accumulated_passages\\n    )\\n    \\n    # Re-search (accumulate)\\n    new_passages = search(refined_query)\\n    accumulated_passages.extend(new_passages)\\n    current_retry += 1\\n```\\n\\n**Core**: Quality Assurance Loop + Progressive Retrieval"
            },
            "csFoundations": [
              "Quality Assurance",
              "Feedback Loop",
              "Progressive Enhancement",
              "RAG Optimization"
            ],
            "impact": {
              "ko": "**ì„±ê³¼**: ë‹µë³€ ì •í™•ë„ **85% â†’ 95%** (10%p â†‘). ì˜¤ë‹µë¥  **15% â†’ 5%** (67% ê°ì†Œ).",
              "en": "**Impact**: Answer accuracy **85% â†’ 95%** (+10%p). Error rate **15% â†’ 5%** (67% reduction)."
            },
            "commits": []
          },
          {
            "id": "progressive-accumulation",
            "title": {
              "ko": "Progressive Context: íŒ¨ì‹œì§€ ëˆ„ì  ì‹œìŠ¤í…œ",
              "en": "Progressive Context: Passage Accumulation System"
            },
            "category": {
              "ko": "ì»¨í…ìŠ¤íŠ¸ê´€ë¦¬",
              "en": "Context Management"
            },
            "icon": "ğŸ“š",
            "problem": {
              "ko": "**ì´ìŠˆ**: ì¬ê²€ìƒ‰ ì‹œ ì´ì „ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë²„ë¦¬ê³  ìƒˆ ê²°ê³¼ë§Œ ì‚¬ìš©í•˜ë©´ ìœ ìš©í•œ ì»¨í…ìŠ¤íŠ¸ê°€ ì†ì‹¤ë¨. íŠ¹íˆ ë³µì¡í•œ ì§ˆë¬¸(ì˜ˆ: \\\"ì‹œìŠ¤í…œ Aì™€ Bì˜ ì—°ë™ ë°©ë²•\\\")ì˜ ê²½ìš° ì²« ê²€ìƒ‰ì—ì„œ A ì •ë³´, ì¬ê²€ìƒ‰ì—ì„œ B ì •ë³´ë¥¼ ì–»ë”ë¼ë„ í†µí•©ì´ ì•ˆ ë˜ì–´ ë¶ˆì™„ì „í•œ ë‹µë³€ ìƒì„±.",
              "en": "**Issue**: Discarding previous search results during re-search and using only new results leads to loss of useful context. Especially for complex questions (e.g., \\\"How to integrate systems A and B\\\"), even if first search retrieves A info and re-search retrieves B info, they aren't integrated, resulting in incomplete answers."
            },
            "solution": {
              "ko": "**í•´ê²°**: `accumulated_passages` ë°°ì—´ë¡œ ì¬ì‹œë„ë§ˆë‹¤ ìƒˆ íŒ¨ì‹œì§€ë¥¼ ëˆ„ì  ì €ì¥. `used_passage_ids` Setìœ¼ë¡œ ì¤‘ë³µ ID í•„í„°ë§í•˜ì—¬ ë™ì¼ ë¬¸ì„œ ì¬í¬í•¨ ë°©ì§€. ìµœì¢… ë‹µë³€ ìƒì„± ì‹œ ëˆ„ì ëœ ëª¨ë“  íŒ¨ì‹œì§€ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µí•˜ì—¬ comprehensiveí•œ ë‹µë³€ ê°€ëŠ¥.",
              "en": "**Solution**: Implemented `accumulated_passages` array to accumulate new passages with each retry. Used `used_passage_ids` Set to filter duplicate IDs, preventing re-inclusion of same documents. Provided all accumulated passages as context for final answer generation, enabling comprehensive responses."
            },
            "technicalDetails": {
              "ko": "```python\\naccumulated_passages = []\\nused_passage_ids = set()\\n\\ndef search_and_accumulate(query):\\n    # ë²¡í„° ê²€ìƒ‰\\n    new_passages = vector_search(query, top_k=5)\\n    \\n    for passage in new_passages:\\n        # ì¤‘ë³µ ì²´í¬\\n        if passage.id not in used_passage_ids:\\n            accumulated_passages.append(passage)\\n            used_passage_ids.add(passage.id)\\n    \\n    return accumulated_passages\\n\\n# ìµœì¢… ë‹µë³€ ìƒì„±\\nanswer = llm.generate(\\n    question=user_question,\\n    context=accumulated_passages  # ëˆ„ì ëœ ëª¨ë“  íŒ¨ì‹œì§€\\n)\\n```\\n\\n**í•µì‹¬**: Stateful Retrieval + Deduplication",
              "en": "```python\\naccumulated_passages = []\\nused_passage_ids = set()\\n\\ndef search_and_accumulate(query):\\n    # Vector search\\n    new_passages = vector_search(query, top_k=5)\\n    \\n    for passage in new_passages:\\n        # Deduplication\\n        if passage.id not in used_passage_ids:\\n            accumulated_passages.append(passage)\\n            used_passage_ids.add(passage.id)\\n    \\n    return accumulated_passages\\n\\n# Final answer generation\\nanswer = llm.generate(\\n    question=user_question,\\n    context=accumulated_passages  # All accumulated passages\\n)\\n```\\n\\n**Core**: Stateful Retrieval + Deduplication"
            },
            "csFoundations": [
              "Stateful Processing",
              "Deduplication",
              "Set Data Structure",
              "Context Window Management"
            ],
            "impact": {
              "ko": "**ì„±ê³¼**: ë³µì¡í•œ ì§ˆë¬¸ ë‹µë³€ ì™„ì„±ë„ **40% í–¥ìƒ**. í‰ê·  ì»¨í…ìŠ¤íŠ¸ í¬ê¸° 3ê°œ â†’ 7ê°œ íŒ¨ì‹œì§€ë¡œ í™•ëŒ€.",
              "en": "**Impact**: Complex query answer completeness **+40%**. Average context size expanded from 3 to 7 passages."
            },
            "commits": []
          },
          {
            "id": "intelligent-refinement",
            "title": {
              "ko": "Intelligent Query: LLM ê¸°ë°˜ ê²€ìƒ‰ì–´ ì •ì œ",
              "en": "Intelligent Query: LLM-Based Search Refinement"
            },
            "category": {
              "ko": "ì¿¼ë¦¬ìµœì í™”",
              "en": "Query Optimization"
            },
            "icon": "ğŸ¯",
            "problem": {
              "ko": "**ì´ìŠˆ**: ì‚¬ìš©ì ì§ˆë¬¸ì´ ëª¨í˜¸í•˜ê±°ë‚˜ ì¼ìƒì–´ë¡œ ì‘ì„±ë˜ë©´ ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨ìœ¨ ì¦ê°€. ì˜ˆ: \\\"ì—ì´ì „íŠ¸ê°€ ì•ˆëŒì•„ê°€ìš”\\\" â†’ ê²€ìƒ‰ ì‹¤íŒ¨ (ê¸°ìˆ  ìš©ì–´ ë¶€ì¬). ë„ë©”ì¸ íŠ¹í™” í‚¤ì›Œë“œ ì—†ì´ëŠ” ì •í™•í•œ ë¬¸ì„œ ë§¤ì¹­ ë¶ˆê°€.",
              "en": "**Issue**: Vector search failure rate increases when user questions are ambiguous or written in casual language. Example: \\\"Agent not working\\\" â†’ search fails (lacks technical terms). Cannot accurately match documents without domain-specific keywords."
            },
            "solution": {
              "ko": "**í•´ê²°**: ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ LLMì´ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ê¸°ìˆ  ìš©ì–´ë¡œ ë³€í™˜. `keywords_to_add` (ì¶”ê°€í•  ë„ë©”ì¸ ìš©ì–´), `keywords_to_remove` (ë¶ˆí•„ìš”í•œ ì¼ìƒì–´), `suggested_query` (ê°œì„ ëœ ì¿¼ë¦¬) ìë™ ìƒì„±. ì˜ˆ: \\\"ì•ˆëŒì•„ê°€ìš”\\\" â†’ [\\\"agent\\\", \\\"error\\\", \\\"execution\\\", \\\"workflow\\\"]",
              "en": "**Solution**: In preprocessing stage, LLM analyzes user question to extract core keywords and convert to technical terms. Auto-generates `keywords_to_add` (domain terms to add), `keywords_to_remove` (unnecessary casual words), `suggested_query` (refined query). Example: \\\"not working\\\" â†’ [\\\"agent\\\", \\\"error\\\", \\\"execution\\\", \\\"workflow\\\"]"
            },
            "technicalDetails": {
              "ko": "```python\\n# í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì •ì œ\\nrefinement_prompt = \\\"\\\"\\\"\\nì‚¬ìš©ì ì§ˆë¬¸: {user_question}\\nì´ì „ ê²€ìƒ‰ ì‹¤íŒ¨: {eval_feedback}\\n\\në‹¤ìŒì„ JSONìœ¼ë¡œ ë°˜í™˜:\\n1. keywords_to_add: ì¶”ê°€í•  ê¸°ìˆ  ìš©ì–´\\n2. keywords_to_remove: ì œê±°í•  ì¼ìƒì–´\\n3. suggested_query: ê°œì„ ëœ ê²€ìƒ‰ ì¿¼ë¦¬\\n\\\"\\\"\\\"\\n\\nrefined = llm.generate(refinement_prompt)\\n# {\\n#   \\\"keywords_to_add\\\": [\\\"FastAPI\\\", \\\"subprocess\\\"],\\n#   \\\"keywords_to_remove\\\": [\\\"ì•ˆëŒì•„ê°€ìš”\\\"],\\n#   \\\"suggested_query\\\": \\\"FastAPI subprocess ì‹¤í–‰ ì˜¤ë¥˜\\\"\\n# }\\n\\n# ê°œì„ ëœ ì¿¼ë¦¬ë¡œ ì¬ê²€ìƒ‰\\npassages = vector_search(refined.suggested_query)\\n```\\n\\n**í•µì‹¬**: Semantic Query Expansion + Domain Adaptation",
              "en": "```python\\n# Keyword extraction and refinement\\nrefinement_prompt = \\\"\\\"\\\"\\nUser question: {user_question}\\nPrevious search failure: {eval_feedback}\\n\\nReturn JSON with:\\n1. keywords_to_add: technical terms to add\\n2. keywords_to_remove: casual words to remove\\n3. suggested_query: refined search query\\n\\\"\\\"\\\"\\n\\nrefined = llm.generate(refinement_prompt)\\n# {\\n#   \\\"keywords_to_add\\\": [\\\"FastAPI\\\", \\\"subprocess\\\"],\\n#   \\\"keywords_to_remove\\\": [\\\"not working\\\"],\\n#   \\\"suggested_query\\\": \\\"FastAPI subprocess execution error\\\"\\n# }\\n\\n# Re-search with refined query\\npassages = vector_search(refined.suggested_query)\\n```\\n\\n**Core**: Semantic Query Expansion + Domain Adaptation"
            },
            "csFoundations": [
              "Query Rewriting",
              "Semantic Search",
              "Natural Language Processing",
              "Domain Adaptation"
            ],
            "impact": {
              "ko": "**ì„±ê³¼**: ê²€ìƒ‰ ì„±ê³µë¥  **70% â†’ 90%** (20%p â†‘). ëª¨í˜¸í•œ ì§ˆë¬¸ ì²˜ë¦¬ ì„±ê³µë¥  **3ë°° í–¥ìƒ**.",
              "en": "**Impact**: Search success rate **70% â†’ 90%** (+20%p). Ambiguous question handling success rate **3x improvement**."
            },
            "commits": []
          }
        ],
        "architecture": [
          {
            "title": {
              "ko": "Self-Corrective RAG Flow",
              "en": "Self-Corrective RAG Flow"
            },
            "description": {
              "ko": "ì‚¬ìš©ì ì§ˆë¬¸ë¶€í„° í’ˆì§ˆ í‰ê°€, ì¬ê²€ìƒ‰, ìµœì¢… ë‹µë³€ê¹Œì§€ì˜ ì „ì²´ Self-Corrective RAG í”„ë¡œì„¸ìŠ¤. í’ˆì§ˆ ì„ê³„ê°’ ë¯¸ë‹¬ ì‹œ ìë™ìœ¼ë¡œ ê²€ìƒ‰ì–´ê°œì„  ë° íŒ¨ì‹œì§€ ëˆ„ì ì„ í†µí•´ ë‹µë³€ í’ˆqualityë¥¼ í–¥ìƒì‹œí‚¤ëŠ” í”¼ë“œë°± ë£¨í”„.",
              "en": "Complete Self-Corrective RAG process from user question through quality evaluation, re-search, to final answer. Feedback loop that automatically refines search queries and accumulates passages to improve answer quality when below threshold."
            },
            "mermaidFilePath": {
              "ko": "/architecture/knowledge-base/self-corrective-flow.mmd",
              "en": "/architecture/knowledge-base/self-corrective-flow-en.mmd"
            }
          },
          {
            "title": {
              "ko": "System Architecture",
              "en": "System Architecture"
            },
            "description": {
              "ko": "Agent Builder ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° ì—”ì§„ê³¼ ì™¸ë¶€ ì„œë¹„ìŠ¤ í†µí•© ì•„í‚¤í…ì²˜. Main, Preprocessing, QnA, Evaluation ì›Œí¬í”Œë¡œìš° ê°„ì˜ ìƒí˜¸ì‘ìš© ë° ë°ì´í„° ê´€ë¦¬ ë°±ì—”ë“œ, LLM í”„ë¡œë°”ì´ë”, ë²¡í„° DBì™€ì˜ ì—°ë™ êµ¬ì¡°.",
              "en": "Workflow engine based on Agent Builder and external service integration architecture. Interactions between Main, Preprocessing, QnA, and Evaluation workflows, plus integration structure with Data Management Backend, LLM Provider, and Vector DB."
            },
            "mermaidFilePath": {
              "ko": "/architecture/knowledge-base/system-architecture.mmd",
              "en": "/architecture/knowledge-base/system-architecture-en.mmd"
            }
          }
        ]
      },
      "featured": false,
      "order": 3
    }
  ]
}
